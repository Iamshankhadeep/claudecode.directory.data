{
  "resources": [
    {
      "id": "nextjs-15-app-router",
      "title": "Next.js 15 App Router + TypeScript",
      "slug": "nextjs-15-app-router-typescript",
      "tagline": "Next.js configuration for intermediate developers",
      "description": "Complete claude.md configuration for Next.js 15 with App Router, TypeScript, Tailwind CSS, and modern development practices.",
      "categoryId": "claude-configs",
      "category": {
        "id": "claude-configs",
        "name": "Claude.md Configurations",
        "slug": "claude-configs",
        "description": "Ready-to-use Claude.md configuration files for different tech stacks and project types.",
        "icon": "ðŸ“‹",
        "color": "#F59E0B"
      },
      "type": "CONFIGURATION",
      "content": "# Claude.md - Next.js 15 App Router Project\n\n## Project Overview\n\nThis is a Next.js 15 application using the App Router, TypeScript, and Tailwind CSS. The project follows modern React patterns with server components, client components, and API routes.\n\n## Technology Stack\n\n- **Framework**: Next.js 15 with App Router\n- **Language**: TypeScript\n- **Styling**: Tailwind CSS\n- **State Management**: React hooks, Context API\n- **API**: Next.js API routes (app/api)\n- **Database**: [Add your database choice]\n- **Authentication**: [Add your auth solution]\n\n## Project Structure\n\n```\nsrc/\nâ”œâ”€â”€ app/                    # App Router pages and layouts\nâ”‚   â”œâ”€â”€ (auth)/            # Route groups\nâ”‚   â”œâ”€â”€ api/               # API routes\nâ”‚   â”œâ”€â”€ globals.css        # Global styles\nâ”‚   â”œâ”€â”€ layout.tsx         # Root layout\nâ”‚   â””â”€â”€ page.tsx           # Home page\nâ”œâ”€â”€ components/            # Reusable React components\nâ”‚   â”œâ”€â”€ ui/               # Base UI components\nâ”‚   â””â”€â”€ forms/            # Form components\nâ”œâ”€â”€ lib/                  # Utility functions\nâ”œâ”€â”€ hooks/                # Custom React hooks\nâ”œâ”€â”€ types/                # TypeScript type definitions\nâ””â”€â”€ utils/                # Helper functions\n```\n\n## Development Guidelines\n\n### Code Style\n- Use TypeScript strict mode\n- Prefer function components with hooks\n- Use server components by default, client components when needed\n- Follow Next.js naming conventions\n- Use Tailwind CSS for styling\n\n### Component Patterns\n- Create reusable UI components in `components/ui/`\n- Use custom hooks for shared logic\n- Implement proper error boundaries\n- Use React.Suspense for loading states\n\n### API Design\n- Use Next.js API routes in `app/api/`\n- Implement proper error handling\n- Use TypeScript for request/response types\n- Follow RESTful conventions\n\n### Performance\n- Optimize images with next/image\n- Use dynamic imports for code splitting\n- Implement proper caching strategies\n- Monitor Core Web Vitals\n\n## Key Commands\n\n- `npm run dev` - Start development server\n- `npm run build` - Build for production\n- `npm run start` - Start production server\n- `npm run lint` - Run ESLint\n- `npm run type-check` - Run TypeScript compiler\n\n## Environment Variables\n\nCreate a `.env.local` file with:\n```\nNEXT_PUBLIC_APP_URL=http://localhost:3000\nDATABASE_URL=your_database_url\nNEXTAUTH_SECRET=your_auth_secret\n```\n\n## Common Patterns\n\n### Server Component\n```tsx\n// app/products/page.tsx\nimport { getProducts } from '@/lib/api';\n\nexport default async function ProductsPage() {\n  const products = await getProducts();\n  \n  return (\n    <div>\n      {products.map(product => (\n        <ProductCard key={product.id} product={product} />\n      ))}\n    </div>\n  );\n}\n```\n\n### Client Component\n```tsx\n'use client';\n\nimport { useState } from 'react';\n\nexport default function Counter() {\n  const [count, setCount] = useState(0);\n  \n  return (\n    <button onClick={() => setCount(count + 1)}>\n      Count: {count}\n    </button>\n  );\n}\n```\n\n### API Route\n```tsx\n// app/api/products/route.ts\nimport { NextRequest, NextResponse } from 'next/server';\n\nexport async function GET(request: NextRequest) {\n  try {\n    const products = await fetchProducts();\n    return NextResponse.json(products);\n  } catch (error) {\n    return NextResponse.json(\n      { error: 'Failed to fetch products' },\n      { status: 500 }\n    );\n  }\n}\n```\n\n## Testing\n\n- Use Jest and React Testing Library\n- Write unit tests for utilities\n- Write integration tests for API routes\n- Use Playwright for e2e testing\n\n## Deployment\n\n- Deploy to Vercel for optimal Next.js experience\n- Configure environment variables\n- Set up monitoring and analytics\n- Enable caching strategies",
      "tags": [
        {
          "tag": {
            "id": "nextjs",
            "name": "nextjs",
            "slug": "nextjs"
          }
        },
        {
          "tag": {
            "id": "typescript",
            "name": "typescript",
            "slug": "typescript"
          }
        },
        {
          "tag": {
            "id": "react",
            "name": "react",
            "slug": "react"
          }
        },
        {
          "tag": {
            "id": "tailwind",
            "name": "tailwind",
            "slug": "tailwind"
          }
        },
        {
          "tag": {
            "id": "app-router",
            "name": "app-router",
            "slug": "app-router"
          }
        }
      ],
      "author": {
        "name": "Claude Code Community",
        "url": "https://github.com/claudecode-community"
      },
      "stats": {
        "votes": 22,
        "copies": 68
      },
      "_count": {
        "votes": 30,
        "copies": 103
      },
      "difficulty": "INTERMEDIATE",
      "language": "TypeScript",
      "framework": "Next.js",
      "lastUpdated": "2024-12-01",
      "featured": false
    },
    {
      "id": "react-vite-typescript",
      "title": "React + Vite + TypeScript",
      "slug": "react-vite-typescript",
      "tagline": "React configuration for beginner developers",
      "description": "Modern React development setup with Vite, TypeScript, and essential tooling for fast development.",
      "categoryId": "claude-configs",
      "category": {
        "id": "claude-configs",
        "name": "Claude.md Configurations",
        "slug": "claude-configs",
        "description": "Ready-to-use Claude.md configuration files for different tech stacks and project types.",
        "icon": "ðŸ“‹",
        "color": "#F59E0B"
      },
      "type": "CONFIGURATION",
      "content": "# Claude.md - React + Vite + TypeScript Project\n\n## Project Overview\n\nThis is a modern React application built with Vite for fast development, TypeScript for type safety, and Tailwind CSS for styling.\n\n## Technology Stack\n\n- **Framework**: React 18\n- **Build Tool**: Vite\n- **Language**: TypeScript\n- **Styling**: Tailwind CSS\n- **State Management**: React hooks, Zustand/Redux Toolkit\n- **Routing**: React Router DOM\n- **Testing**: Vitest, React Testing Library\n\n## Project Structure\n\n```\nsrc/\nâ”œâ”€â”€ components/           # React components\nâ”‚   â”œâ”€â”€ ui/              # Reusable UI components\nâ”‚   â”œâ”€â”€ forms/           # Form components\nâ”‚   â””â”€â”€ layout/          # Layout components\nâ”œâ”€â”€ pages/               # Page components\nâ”œâ”€â”€ hooks/               # Custom React hooks\nâ”œâ”€â”€ store/               # State management\nâ”œâ”€â”€ utils/               # Utility functions\nâ”œâ”€â”€ types/               # TypeScript types\nâ”œâ”€â”€ styles/              # CSS and Tailwind styles\nâ””â”€â”€ main.tsx            # Application entry point\n```\n\n## Development Guidelines\n\n### Code Style\n- Use functional components with hooks\n- Implement TypeScript strict mode\n- Use Tailwind CSS for styling\n- Follow React best practices\n- Use ESLint and Prettier\n\n### Component Architecture\n- Create small, focused components\n- Use custom hooks for business logic\n- Implement proper prop typing\n- Use React.memo for performance optimization\n\n### State Management\n- Use React hooks for local state\n- Use Zustand or Redux Toolkit for global state\n- Implement proper data fetching patterns\n- Use React Query for server state\n\n## Key Commands\n\n- `npm run dev` - Start development server\n- `npm run build` - Build for production\n- `npm run preview` - Preview production build\n- `npm run test` - Run tests\n- `npm run lint` - Run linter\n\n## Environment Variables\n\nCreate a `.env` file:\n```\nVITE_API_URL=http://localhost:8000/api\nVITE_APP_TITLE=My React App\n```\n\n## Common Patterns\n\n### Component with TypeScript\n```tsx\ninterface ButtonProps {\n  variant?: 'primary' | 'secondary';\n  children: React.ReactNode;\n  onClick?: () => void;\n}\n\nexport const Button: React.FC<ButtonProps> = ({ \n  variant = 'primary', \n  children, \n  onClick \n}) => {\n  return (\n    <button\n      className={`btn btn-${variant}`}\n      onClick={onClick}\n    >\n      {children}\n    </button>\n  );\n};\n```\n\n### Custom Hook\n```tsx\nimport { useState, useEffect } from 'react';\n\nexport function useApi<T>(url: string) {\n  const [data, setData] = useState<T | null>(null);\n  const [loading, setLoading] = useState(true);\n  const [error, setError] = useState<string | null>(null);\n\n  useEffect(() => {\n    fetch(url)\n      .then(res => res.json())\n      .then(setData)\n      .catch(err => setError(err.message))\n      .finally(() => setLoading(false));\n  }, [url]);\n\n  return { data, loading, error };\n}\n```\n\n### Route Configuration\n```tsx\nimport { createBrowserRouter } from 'react-router-dom';\nimport { HomePage, AboutPage, ContactPage } from './pages';\n\nexport const router = createBrowserRouter([\n  {\n    path: '/',\n    element: <HomePage />\n  },\n  {\n    path: '/about',\n    element: <AboutPage />\n  },\n  {\n    path: '/contact',\n    element: <ContactPage />\n  }\n]);\n```\n\n## Performance Tips\n\n- Use React.lazy for code splitting\n- Implement virtual scrolling for large lists\n- Optimize bundle size with tree shaking\n- Use React DevTools for debugging\n\n## Testing\n\n- Write unit tests for components\n- Test custom hooks\n- Use MSW for API mocking\n- Implement integration tests\n\n## Deployment\n\n- Build optimized bundle with `npm run build`\n- Deploy to Netlify, Vercel, or similar\n- Configure environment variables\n- Set up CI/CD pipeline",
      "tags": [
        {
          "tag": {
            "id": "react",
            "name": "react",
            "slug": "react"
          }
        },
        {
          "tag": {
            "id": "vite",
            "name": "vite",
            "slug": "vite"
          }
        },
        {
          "tag": {
            "id": "typescript",
            "name": "typescript",
            "slug": "typescript"
          }
        },
        {
          "tag": {
            "id": "tailwind",
            "name": "tailwind",
            "slug": "tailwind"
          }
        },
        {
          "tag": {
            "id": "spa",
            "name": "spa",
            "slug": "spa"
          }
        }
      ],
      "author": {
        "name": "Claude Code Community",
        "url": "https://github.com/claudecode-community"
      },
      "stats": {
        "votes": 50,
        "copies": 142
      },
      "_count": {
        "votes": 50,
        "copies": 50
      },
      "difficulty": "BEGINNER",
      "language": "TypeScript",
      "framework": "React",
      "lastUpdated": "2024-12-01",
      "featured": false
    },
    {
      "id": "vue3-composition-api",
      "title": "Vue 3 + Composition API + TypeScript",
      "slug": "vue3-composition-api-typescript",
      "tagline": "Vue.js configuration for intermediate developers",
      "description": "Modern Vue 3 application with Composition API, TypeScript, and Vue ecosystem best practices.",
      "categoryId": "claude-configs",
      "category": {
        "id": "claude-configs",
        "name": "Claude.md Configurations",
        "slug": "claude-configs",
        "description": "Ready-to-use Claude.md configuration files for different tech stacks and project types.",
        "icon": "ðŸ“‹",
        "color": "#F59E0B"
      },
      "type": "CONFIGURATION",
      "content": "# Claude.md - Vue 3 + Composition API + TypeScript Project\n\n## Project Overview\n\nThis is a Vue 3 application using the Composition API, TypeScript, and modern Vue.js development practices with Vite as the build tool.\n\n## Technology Stack\n\n- **Framework**: Vue 3\n- **API Style**: Composition API\n- **Language**: TypeScript\n- **Build Tool**: Vite\n- **State Management**: Pinia\n- **Routing**: Vue Router 4\n- **Styling**: CSS Modules, SCSS\n\n## Project Structure\n\n```\nsrc/\nâ”œâ”€â”€ components/          # Vue components\nâ”‚   â”œâ”€â”€ ui/             # Base UI components\nâ”‚   â””â”€â”€ forms/          # Form components\nâ”œâ”€â”€ views/              # Page components (routes)\nâ”œâ”€â”€ composables/        # Composition API functions\nâ”œâ”€â”€ stores/             # Pinia stores\nâ”œâ”€â”€ router/             # Vue Router configuration\nâ”œâ”€â”€ utils/              # Utility functions\nâ”œâ”€â”€ types/              # TypeScript type definitions\nâ””â”€â”€ main.ts            # Application entry point\n```\n\n## Development Guidelines\n\n### Code Style  \n- Use Composition API over Options API\n- Implement TypeScript strict mode\n- Use `<script setup>` syntax\n- Follow Vue.js style guide\n- Use single-file components (.vue)\n\n### Component Architecture\n- Create composable functions for reusable logic\n- Use props validation with TypeScript\n- Implement proper event handling\n- Use Vue 3 teleport for modals/overlays\n\n### State Management\n- Use Pinia for global state management\n- Create typed stores\n- Use composables for local state\n- Implement proper reactive patterns\n\n## Key Commands\n\n- `npm run dev` - Start development server  \n- `npm run build` - Build for production\n- `npm run preview` - Preview production build\n- `npm run test` - Run unit tests\n- `npm run type-check` - TypeScript checking\n\n## Environment Variables\n\nCreate a `.env` file:\n```\nVITE_API_BASE_URL=http://localhost:3000/api\nVITE_APP_TITLE=My Vue App\n```\n\n## Common Patterns\n\n### Component with Composition API\n```vue\n<template>\n  <div class=\"user-profile\">\n    <h2>{{ user.name }}</h2>\n    <p>{{ user.email }}</p>\n    <button @click=\"updateProfile\">Update</button>\n  </div>\n</template>\n\n<script setup lang=\"ts\">\ninterface User {\n  id: number;\n  name: string;\n  email: string;\n}\n\ninterface Props {\n  userId: number;\n}\n\nconst props = defineProps<Props>();\nconst emit = defineEmits<{\n  update: [user: User];\n}>();\n\nconst user = ref<User | null>(null);\nconst loading = ref(false);\n\nconst fetchUser = async (id: number) => {\n  loading.value = true;\n  try {\n    const response = await fetch(`/api/users/${id}`);\n    user.value = await response.json();\n  } finally {\n    loading.value = false;\n  }\n};\n\nconst updateProfile = () => {\n  if (user.value) {\n    emit('update', user.value);\n  }\n};\n\nonMounted(() => {\n  fetchUser(props.userId);\n});\n</script>\n```\n\n### Composable Function\n```ts\n// composables/useApi.ts\nimport { ref, Ref } from 'vue';\n\nexport function useApi<T>(url: string) {\n  const data: Ref<T | null> = ref(null);\n  const loading = ref(false);\n  const error = ref<string | null>(null);\n\n  const execute = async () => {\n    loading.value = true;\n    error.value = null;\n    \n    try {\n      const response = await fetch(url);\n      if (!response.ok) throw new Error(response.statusText);\n      data.value = await response.json();\n    } catch (err) {\n      error.value = err instanceof Error ? err.message : 'Unknown error';\n    } finally {\n      loading.value = false;\n    }\n  };\n\n  return {\n    data: readonly(data),\n    loading: readonly(loading),\n    error: readonly(error),\n    execute\n  };\n}\n```\n\n### Pinia Store\n```ts\n// stores/user.ts\nimport { defineStore } from 'pinia';\n\ninterface User {\n  id: number;\n  name: string;\n  email: string;\n}\n\nexport const useUserStore = defineStore('user', () => {\n  const users = ref<User[]>([]);\n  const currentUser = ref<User | null>(null);\n\n  const fetchUsers = async () => {\n    const response = await fetch('/api/users');\n    users.value = await response.json();\n  };\n\n  const setCurrentUser = (user: User) => {\n    currentUser.value = user;\n  };\n\n  return {\n    users: readonly(users),\n    currentUser: readonly(currentUser),\n    fetchUsers,\n    setCurrentUser\n  };\n});\n```\n\n### Router Configuration\n```ts\n// router/index.ts\nimport { createRouter, createWebHistory } from 'vue-router';\nimport Home from '@/views/Home.vue';\n\nconst router = createRouter({\n  history: createWebHistory(),\n  routes: [\n    {\n      path: '/',\n      name: 'Home',\n      component: Home\n    },\n    {\n      path: '/about',\n      name: 'About',\n      component: () => import('@/views/About.vue')\n    }\n  ]\n});\n\nexport default router;\n```\n\n## Performance Tips\n\n- Use `v-memo` for expensive list rendering\n- Implement lazy loading with `defineAsyncComponent`\n- Use `shallowRef` for large objects\n- Optimize with `markRaw` for non-reactive data\n\n## Testing\n\n- Use Vue Test Utils with Vitest\n- Test components in isolation\n- Mock composables and stores\n- Write integration tests for complex flows\n\n## Deployment\n\n- Build with `npm run build`\n- Deploy to Netlify, Vercel, or similar\n- Configure build environment variables\n- Set up proper routing for SPA",
      "tags": [
        {
          "tag": {
            "id": "vue",
            "name": "vue",
            "slug": "vue"
          }
        },
        {
          "tag": {
            "id": "vue3",
            "name": "vue3",
            "slug": "vue3"
          }
        },
        {
          "tag": {
            "id": "typescript",
            "name": "typescript",
            "slug": "typescript"
          }
        },
        {
          "tag": {
            "id": "composition-api",
            "name": "composition-api",
            "slug": "composition-api"
          }
        },
        {
          "tag": {
            "id": "pinia",
            "name": "pinia",
            "slug": "pinia"
          }
        }
      ],
      "author": {
        "name": "Claude Code Community",
        "url": "https://github.com/claudecode-community"
      },
      "stats": {
        "votes": 55,
        "copies": 94
      },
      "_count": {
        "votes": 43,
        "copies": 117
      },
      "difficulty": "INTERMEDIATE",
      "language": "TypeScript",
      "framework": "Vue.js",
      "lastUpdated": "2024-12-01",
      "featured": false
    },
    {
      "id": "astro-content-collections",
      "title": "Astro + Content Collections + TypeScript",
      "slug": "astro-content-collections-typescript",
      "tagline": "Astro configuration for intermediate developers",
      "description": "Static site generation with Astro, content collections, and TypeScript for fast, SEO-friendly websites.",
      "categoryId": "claude-configs",
      "category": {
        "id": "claude-configs",
        "name": "Claude.md Configurations",
        "slug": "claude-configs",
        "description": "Ready-to-use Claude.md configuration files for different tech stacks and project types.",
        "icon": "ðŸ“‹",
        "color": "#F59E0B"
      },
      "type": "CONFIGURATION",
      "content": "# Claude.md - Astro + Content Collections + TypeScript Project\n\n## Project Overview\n\nThis is an Astro project utilizing content collections, TypeScript, and static site generation for optimal performance and SEO.\n\n## Technology Stack\n\n- **Framework**: Astro\n- **Language**: TypeScript\n- **Content**: Content Collections (Markdown/MDX)\n- **Styling**: Tailwind CSS, CSS Modules\n- **Integrations**: React, Vue, or Svelte (as needed)\n- **Deployment**: Static hosting (Netlify, Vercel)\n\n## Project Structure\n\n```\nsrc/\nâ”œâ”€â”€ components/          # Astro/Framework components\nâ”œâ”€â”€ content/            # Content collections\nâ”‚   â”œâ”€â”€ blog/          # Blog posts\nâ”‚   â”œâ”€â”€ docs/          # Documentation\nâ”‚   â””â”€â”€ config.ts      # Content config\nâ”œâ”€â”€ layouts/           # Page layouts\nâ”œâ”€â”€ pages/             # Routes and pages\nâ”œâ”€â”€ styles/            # Global styles\nâ””â”€â”€ utils/             # Utility functions\n```\n\n## Development Guidelines\n\n### Content Strategy\n- Use Content Collections for structured content\n- Write content in Markdown/MDX\n- Implement proper frontmatter schemas\n- Organize content logically\n\n### Component Architecture\n- Create reusable Astro components\n- Use framework components sparingly\n- Implement proper TypeScript typing\n- Optimize for static generation\n\n### Performance\n- Minimize JavaScript bundle size\n- Use Astro's partial hydration\n- Optimize images with Astro's image service\n- Implement proper caching strategies\n\n## Key Commands\n\n- `npm run dev` - Start development server\n- `npm run build` - Build static site\n- `npm run preview` - Preview built site\n- `npm run astro` - Run Astro CLI commands\n\n## Content Collections Configuration\n\n```ts\n// src/content/config.ts\nimport { defineCollection, z } from 'astro:content';\n\nconst blogCollection = defineCollection({\n  type: 'content',\n  schema: z.object({\n    title: z.string(),\n    description: z.string(),\n    pubDate: z.date(),\n    author: z.string(),\n    tags: z.array(z.string()),\n    image: z.string().optional(),\n  })\n});\n\nconst docsCollection = defineCollection({\n  type: 'content',\n  schema: z.object({\n    title: z.string(),\n    description: z.string(),\n    order: z.number(),\n    category: z.string(),\n  })\n});\n\nexport const collections = {\n  'blog': blogCollection,\n  'docs': docsCollection,\n};\n```\n\n## Common Patterns\n\n### Astro Component\n```astro\n---\n// src/components/BlogCard.astro\nexport interface Props {\n  title: string;\n  description: string;\n  pubDate: Date;\n  href: string;\n}\n\nconst { title, description, pubDate, href } = Astro.props;\n---\n\n<article class=\"blog-card\">\n  <h3><a href={href}>{title}</a></h3>\n  <p>{description}</p>\n  <time datetime={pubDate.toISOString()}>\n    {pubDate.toLocaleDateString()}\n  </time>\n</article>\n\n<style>\n.blog-card {\n  border: 1px solid #e2e8f0;\n  border-radius: 8px;\n  padding: 1.5rem;\n  transition: transform 0.2s;\n}\n\n.blog-card:hover {\n  transform: translateY(-2px);\n}\n</style>\n```\n\n### Page with Content Collection\n```astro\n---\n// src/pages/blog/index.astro\nimport { getCollection } from 'astro:content';\nimport BlogCard from '../../components/BlogCard.astro';\nimport Layout from '../../layouts/Layout.astro';\n\nconst blogPosts = await getCollection('blog');\nconst sortedPosts = blogPosts.sort(\n  (a, b) => b.data.pubDate.valueOf() - a.data.pubDate.valueOf()\n);\n---\n\n<Layout title=\"Blog\">\n  <main>\n    <h1>Blog Posts</h1>\n    <section class=\"posts-grid\">\n      {sortedPosts.map((post) => (\n        <BlogCard\n          title={post.data.title}\n          description={post.data.description}\n          pubDate={post.data.pubDate}\n          href={`/blog/${post.slug}`}\n        />\n      ))}\n    </section>\n  </main>\n</Layout>\n```\n\n### Dynamic Page Generation\n```astro\n---\n// src/pages/blog/[...slug].astro\nimport { getCollection } from 'astro:content';\nimport BlogLayout from '../../layouts/BlogLayout.astro';\n\nexport async function getStaticPaths() {\n  const blogEntries = await getCollection('blog');\n  return blogEntries.map(entry => ({\n    params: { slug: entry.slug },\n    props: { entry },\n  }));\n}\n\nconst { entry } = Astro.props;\nconst { Content } = await entry.render();\n---\n\n<BlogLayout frontmatter={entry.data}>\n  <Content />\n</BlogLayout>\n```\n\n### Integration with React Component\n```tsx\n// src/components/SearchBox.tsx\nimport { useState } from 'react';\n\ninterface SearchBoxProps {\n  placeholder?: string;\n  onSearch: (query: string) => void;\n}\n\nexport default function SearchBox({ \n  placeholder = \"Search...\", \n  onSearch \n}: SearchBoxProps) {\n  const [query, setQuery] = useState('');\n\n  const handleSubmit = (e: React.FormEvent) => {\n    e.preventDefault();\n    onSearch(query);\n  };\n\n  return (\n    <form onSubmit={handleSubmit}>\n      <input\n        type=\"text\"\n        value={query}\n        onChange={(e) => setQuery(e.target.value)}\n        placeholder={placeholder}\n      />\n      <button type=\"submit\">Search</button>\n    </form>\n  );\n}\n```\n\n### Using React Component in Astro\n```astro\n---\nimport SearchBox from '../components/SearchBox.tsx';\n---\n\n<SearchBox \n  client:load \n  placeholder=\"Search posts...\"\n  onSearch={(query) => console.log(query)}\n/>\n```\n\n## SEO and Performance\n\n- Use proper meta tags in layouts\n- Implement structured data\n- Optimize Core Web Vitals\n- Use Astro's built-in image optimization\n- Implement proper sitemap generation\n\n## Content Management\n\n- Use frontmatter for metadata\n- Organize content in logical collections\n- Implement content validation with Zod\n- Use MDX for interactive content\n\n## Deployment\n\n- Build static site with `npm run build`\n- Deploy to any static hosting provider\n- Configure build environment variables\n- Set up continuous deployment from Git",
      "tags": [
        {
          "tag": {
            "id": "astro",
            "name": "astro",
            "slug": "astro"
          }
        },
        {
          "tag": {
            "id": "typescript",
            "name": "typescript",
            "slug": "typescript"
          }
        },
        {
          "tag": {
            "id": "ssg",
            "name": "ssg",
            "slug": "ssg"
          }
        },
        {
          "tag": {
            "id": "content-collections",
            "name": "content-collections",
            "slug": "content-collections"
          }
        },
        {
          "tag": {
            "id": "markdown",
            "name": "markdown",
            "slug": "markdown"
          }
        }
      ],
      "author": {
        "name": "Claude Code Community",
        "url": "https://github.com/claudecode-community"
      },
      "stats": {
        "votes": 39,
        "copies": 59
      },
      "_count": {
        "votes": 17,
        "copies": 102
      },
      "difficulty": "INTERMEDIATE",
      "language": "TypeScript",
      "framework": "Astro",
      "lastUpdated": "2024-12-01",
      "featured": false
    },
    {
      "id": "sveltekit-app",
      "title": "SvelteKit + TypeScript + TailwindCSS",
      "slug": "sveltekit-typescript-tailwind",
      "tagline": "SvelteKit configuration for intermediate developers",
      "description": "Full-stack SvelteKit application with TypeScript, TailwindCSS, and modern Svelte development patterns.",
      "categoryId": "claude-configs",
      "category": {
        "id": "claude-configs",
        "name": "Claude.md Configurations",
        "slug": "claude-configs",
        "description": "Ready-to-use Claude.md configuration files for different tech stacks and project types.",
        "icon": "ðŸ“‹",
        "color": "#F59E0B"
      },
      "type": "CONFIGURATION",
      "content": "# Claude.md - SvelteKit + TypeScript + TailwindCSS Project\n\n## Project Overview\n\nThis is a SvelteKit application with TypeScript and TailwindCSS, providing full-stack capabilities with server-side rendering and static site generation.\n\n## Technology Stack\n\n- **Framework**: SvelteKit\n- **Language**: TypeScript\n- **Styling**: TailwindCSS\n- **State Management**: Svelte stores\n- **Database**: [Your choice - Prisma, Drizzle, etc.]\n- **Authentication**: [Your choice - Auth.js, etc.]\n- **Deployment**: Vercel, Netlify, or Node.js\n\n## Project Structure\n\n```\nsrc/\nâ”œâ”€â”€ lib/                # Shared utilities and components\nâ”‚   â”œâ”€â”€ components/     # Reusable Svelte components\nâ”‚   â”œâ”€â”€ stores/         # Svelte stores\nâ”‚   â””â”€â”€ utils/          # Utility functions\nâ”œâ”€â”€ routes/             # File-based routing\nâ”‚   â”œâ”€â”€ api/           # API endpoints\nâ”‚   â”œâ”€â”€ +layout.svelte # Root layout\nâ”‚   â””â”€â”€ +page.svelte   # Home page\nâ”œâ”€â”€ app.html           # HTML template\nâ””â”€â”€ app.css           # Global styles\n```\n\n## Development Guidelines\n\n### Code Style\n- Use TypeScript for type safety\n- Follow Svelte conventions\n- Use TailwindCSS for styling\n- Implement proper component composition\n- Use SvelteKit's file-based routing\n\n### Component Architecture\n- Create reusable components in `lib/components/`\n- Use Svelte stores for global state\n- Implement proper prop typing\n- Use slots for component composition\n\n### Server-Side Features\n- Use load functions for data fetching\n- Implement API routes in `routes/api/`\n- Use form actions for form handling\n- Implement proper error handling\n\n## Key Commands\n\n- `npm run dev` - Start development server\n- `npm run build` - Build for production\n- `npm run preview` - Preview production build\n- `npm run check` - Run Svelte check\n- `npm run lint` - Run ESLint\n\n## Environment Variables\n\nCreate a `.env` file:\n```\nDATABASE_URL=your_database_url\nSECRET_KEY=your_secret_key\nPUBLIC_API_URL=http://localhost:5173/api\n```\n\n## Common Patterns\n\n### Svelte Component with TypeScript\n```svelte\n<!-- lib/components/UserCard.svelte -->\n<script lang=\"ts\">\n  export let user: {\n    id: number;\n    name: string;\n    email: string;\n    avatar?: string;\n  };\n  \n  export let showEmail = true;\n  export let clickable = false;\n  \n  import { createEventDispatcher } from 'svelte';\n  \n  const dispatch = createEventDispatcher<{\n    click: { user: typeof user };\n  }>();\n  \n  function handleClick() {\n    if (clickable) {\n      dispatch('click', { user });\n    }\n  }\n</script>\n\n<div \n  class=\"user-card\"\n  class:clickable\n  on:click={handleClick}\n  on:keydown={(e) => e.key === 'Enter' && handleClick()}\n  role={clickable ? 'button' : undefined}\n  tabindex={clickable ? 0 : undefined}\n>\n  {#if user.avatar}\n    <img src={user.avatar} alt=\"{user.name}'s avatar\" />\n  {/if}\n  \n  <div class=\"user-info\">\n    <h3>{user.name}</h3>\n    {#if showEmail}\n      <p>{user.email}</p>\n    {/if}\n  </div>\n</div>\n\n<style>\n  .user-card {\n    @apply p-4 border rounded-lg;\n  }\n  \n  .clickable {\n    @apply cursor-pointer hover:bg-gray-50 transition-colors;\n  }\n</style>\n```\n\n### Page with Load Function\n```svelte\n<!-- routes/users/+page.svelte -->\n<script lang=\"ts\">\n  import type { PageData } from './$types';\n  import UserCard from '$lib/components/UserCard.svelte';\n  \n  export let data: PageData;\n  \n  function handleUserClick(event: CustomEvent<{ user: typeof data.users[0] }>) {\n    console.log('User clicked:', event.detail.user);\n  }\n</script>\n\n<svelte:head>\n  <title>Users</title>\n  <meta name=\"description\" content=\"List of all users\" />\n</svelte:head>\n\n<main class=\"container mx-auto px-4 py-8\">\n  <h1 class=\"text-3xl font-bold mb-8\">Users</h1>\n  \n  <div class=\"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6\">\n    {#each data.users as user (user.id)}\n      <UserCard \n        {user} \n        clickable \n        on:click={handleUserClick} \n      />\n    {/each}\n  </div>\n</main>\n```\n\n### Load Function\n```ts\n// routes/users/+page.ts\nimport type { PageLoad } from './$types';\n\nexport const load: PageLoad = async ({ fetch }) => {\n  const response = await fetch('/api/users');\n  \n  if (!response.ok) {\n    throw new Error('Failed to load users');\n  }\n  \n  const users = await response.json();\n  \n  return {\n    users\n  };\n};\n```\n\n### API Route\n```ts\n// routes/api/users/+server.ts\nimport { json } from '@sveltejs/kit';\nimport type { RequestHandler } from './$types';\n\nexport const GET: RequestHandler = async () => {\n  try {\n    // Fetch users from database\n    const users = await getUsersFromDatabase();\n    \n    return json(users);\n  } catch (error) {\n    return json(\n      { error: 'Failed to fetch users' },\n      { status: 500 }\n    );\n  }\n};\n\nexport const POST: RequestHandler = async ({ request }) => {\n  try {\n    const userData = await request.json();\n    const user = await createUser(userData);\n    \n    return json(user, { status: 201 });\n  } catch (error) {\n    return json(\n      { error: 'Failed to create user' },\n      { status: 400 }\n    );\n  }\n};\n```\n\n### Svelte Store\n```ts\n// lib/stores/user.ts\nimport { writable } from 'svelte/store';\n\ninterface User {\n  id: number;\n  name: string;\n  email: string;\n}\n\nfunction createUserStore() {\n  const { subscribe, set, update } = writable<User[]>([]);\n  \n  return {\n    subscribe,\n    set,\n    add: (user: User) => update(users => [...users, user]),\n    remove: (id: number) => update(users => users.filter(u => u.id !== id)),\n    clear: () => set([])\n  };\n}\n\nexport const users = createUserStore();\n```\n\n### Form Actions\n```ts\n// routes/contact/+page.server.ts\nimport { fail } from '@sveltejs/kit';\nimport type { Actions } from './$types';\n\nexport const actions: Actions = {\n  default: async ({ request }) => {\n    const data = await request.formData();\n    const name = data.get('name') as string;\n    const email = data.get('email') as string;\n    const message = data.get('message') as string;\n    \n    if (!name || !email || !message) {\n      return fail(400, {\n        error: 'All fields are required',\n        name,\n        email,\n        message\n      });\n    }\n    \n    try {\n      await sendContactEmail({ name, email, message });\n      return { success: true };\n    } catch (error) {\n      return fail(500, {\n        error: 'Failed to send message',\n        name,\n        email,\n        message\n      });\n    }\n  }\n};\n```\n\n## Performance Tips\n\n- Use SvelteKit's preloading features\n- Implement proper code splitting\n- Optimize images and assets\n- Use SSR/SSG appropriately\n- Implement proper caching strategies\n\n## Testing\n\n- Use Vitest for unit testing\n- Test components with @testing-library/svelte\n- Use Playwright for e2e testing\n- Mock API calls in tests\n\n## Deployment\n\n- Configure adapter for your deployment target\n- Set up environment variables\n- Implement proper build optimization\n- Configure caching and CDN",
      "tags": [
        {
          "tag": {
            "id": "svelte",
            "name": "svelte",
            "slug": "svelte"
          }
        },
        {
          "tag": {
            "id": "sveltekit",
            "name": "sveltekit",
            "slug": "sveltekit"
          }
        },
        {
          "tag": {
            "id": "typescript",
            "name": "typescript",
            "slug": "typescript"
          }
        },
        {
          "tag": {
            "id": "tailwind",
            "name": "tailwind",
            "slug": "tailwind"
          }
        },
        {
          "tag": {
            "id": "fullstack",
            "name": "fullstack",
            "slug": "fullstack"
          }
        }
      ],
      "author": {
        "name": "Claude Code Community",
        "url": "https://github.com/claudecode-community"
      },
      "stats": {
        "votes": 22,
        "copies": 123
      },
      "_count": {
        "votes": 26,
        "copies": 202
      },
      "difficulty": "INTERMEDIATE",
      "language": "TypeScript",
      "framework": "SvelteKit",
      "lastUpdated": "2024-12-01",
      "featured": false
    },
    {
      "id": "nodejs-express-typescript",
      "title": "Node.js Express + TypeScript API",
      "slug": "nodejs-express-typescript-api",
      "tagline": "Express.js configuration for intermediate developers",
      "description": "RESTful API built with Node.js, Express, TypeScript, and modern backend development practices.",
      "categoryId": "claude-configs",
      "category": {
        "id": "claude-configs",
        "name": "Claude.md Configurations",
        "slug": "claude-configs",
        "description": "Ready-to-use Claude.md configuration files for different tech stacks and project types.",
        "icon": "ðŸ“‹",
        "color": "#F59E0B"
      },
      "type": "CONFIGURATION",
      "content": "# Claude.md - Node.js Express + TypeScript API\n\n## Project Overview\n\nThis is a RESTful API built with Node.js, Express, and TypeScript, following modern backend development practices with proper error handling, validation, and database integration.\n\n## Technology Stack\n\n- **Runtime**: Node.js\n- **Framework**: Express.js\n- **Language**: TypeScript\n- **Database**: PostgreSQL with Prisma ORM\n- **Authentication**: JWT with bcrypt\n- **Validation**: Zod or Joi\n- **Testing**: Jest with Supertest\n- **Documentation**: Swagger/OpenAPI\n\n## Project Structure\n\n```\nsrc/\nâ”œâ”€â”€ controllers/        # Request handlers\nâ”œâ”€â”€ middleware/         # Custom middleware\nâ”œâ”€â”€ models/            # Database models\nâ”œâ”€â”€ routes/            # API routes\nâ”œâ”€â”€ services/          # Business logic\nâ”œâ”€â”€ utils/             # Utility functions\nâ”œâ”€â”€ types/             # TypeScript types\nâ”œâ”€â”€ config/            # Configuration files\nâ””â”€â”€ app.ts            # Express app setup\n```\n\n## Development Guidelines\n\n### Code Style\n- Use TypeScript strict mode\n- Follow REST API conventions\n- Implement proper error handling\n- Use middleware for cross-cutting concerns\n- Follow SOLID principles\n\n### API Design\n- Use consistent naming conventions\n- Implement proper HTTP status codes\n- Use pagination for list endpoints\n- Implement proper filtering and sorting\n- Follow REST resource patterns\n\n### Security\n- Implement authentication and authorization\n- Use HTTPS in production\n- Validate all inputs\n- Implement rate limiting\n- Use security headers\n\n## Key Commands\n\n- `npm run dev` - Start development server with nodemon\n- `npm run build` - Compile TypeScript\n- `npm start` - Start production server\n- `npm test` - Run tests\n- `npm run lint` - Run ESLint\n\n## Environment Variables\n\nCreate a `.env` file:\n```\nNODE_ENV=development\nPORT=3000\nDATABASE_URL=postgresql://user:password@localhost:5432/myapp\nJWT_SECRET=your-super-secret-jwt-key\nBCRYPT_ROUNDS=12\nCORS_ORIGIN=http://localhost:3001\n```\n\n## Common Patterns\n\n### Express App Setup\n```ts\n// src/app.ts\nimport express from 'express';\nimport cors from 'cors';\nimport helmet from 'helmet';\nimport morgan from 'morgan';\nimport { errorHandler } from './middleware/errorHandler';\nimport { notFound } from './middleware/notFound';\nimport authRoutes from './routes/auth';\nimport userRoutes from './routes/users';\n\nconst app = express();\n\n// Middleware\napp.use(helmet());\napp.use(cors({\n  origin: process.env.CORS_ORIGIN || 'http://localhost:3001',\n  credentials: true\n}));\napp.use(morgan('combined'));\napp.use(express.json({ limit: '10mb' }));\napp.use(express.urlencoded({ extended: true }));\n\n// Routes\napp.use('/api/auth', authRoutes);\napp.use('/api/users', userRoutes);\n\n// Error handling\napp.use(notFound);\napp.use(errorHandler);\n\nexport default app;\n```\n\n### Controller Pattern\n```ts\n// src/controllers/userController.ts\nimport { Request, Response, NextFunction } from 'express';\nimport { userService } from '../services/userService';\nimport { CreateUserSchema, UpdateUserSchema } from '../types/user';\n\nexport const userController = {\n  async getUsers(req: Request, res: Response, next: NextFunction) {\n    try {\n      const { page = 1, limit = 10, search } = req.query;\n      const users = await userService.getUsers({\n        page: Number(page),\n        limit: Number(limit),\n        search: search as string\n      });\n      \n      res.json({\n        success: true,\n        data: users,\n        pagination: {\n          page: Number(page),\n          limit: Number(limit),\n          total: users.length\n        }\n      });\n    } catch (error) {\n      next(error);\n    }\n  },\n\n  async createUser(req: Request, res: Response, next: NextFunction) {\n    try {\n      const validatedData = CreateUserSchema.parse(req.body);\n      const user = await userService.createUser(validatedData);\n      \n      res.status(201).json({\n        success: true,\n        data: user,\n        message: 'User created successfully'\n      });\n    } catch (error) {\n      next(error);\n    }\n  },\n\n  async getUserById(req: Request, res: Response, next: NextFunction) {\n    try {\n      const { id } = req.params;\n      const user = await userService.getUserById(id);\n      \n      if (!user) {\n        return res.status(404).json({\n          success: false,\n          message: 'User not found'\n        });\n      }\n      \n      res.json({\n        success: true,\n        data: user\n      });\n    } catch (error) {\n      next(error);\n    }\n  }\n};\n```\n\n### Service Layer\n```ts\n// src/services/userService.ts\nimport { prisma } from '../config/database';\nimport { hashPassword } from '../utils/auth';\nimport type { CreateUserData, UpdateUserData } from '../types/user';\n\nexport const userService = {\n  async getUsers(options: {\n    page: number;\n    limit: number;\n    search?: string;\n  }) {\n    const { page, limit, search } = options;\n    const skip = (page - 1) * limit;\n    \n    const where = search ? {\n      OR: [\n        { name: { contains: search, mode: 'insensitive' } },\n        { email: { contains: search, mode: 'insensitive' } }\n      ]\n    } : {};\n\n    return await prisma.user.findMany({\n      where,\n      skip,\n      take: limit,\n      select: {\n        id: true,\n        name: true,\n        email: true,\n        createdAt: true,\n        updatedAt: true\n      }\n    });\n  },\n\n  async createUser(data: CreateUserData) {\n    const hashedPassword = await hashPassword(data.password);\n    \n    return await prisma.user.create({\n      data: {\n        ...data,\n        password: hashedPassword\n      },\n      select: {\n        id: true,\n        name: true,\n        email: true,\n        createdAt: true\n      }\n    });\n  },\n\n  async getUserById(id: string) {\n    return await prisma.user.findUnique({\n      where: { id },\n      select: {\n        id: true,\n        name: true,\n        email: true,\n        createdAt: true,\n        updatedAt: true\n      }\n    });\n  }\n};\n```\n\n### Authentication Middleware\n```ts\n// src/middleware/auth.ts\nimport { Request, Response, NextFunction } from 'express';\nimport jwt from 'jsonwebtoken';\nimport { prisma } from '../config/database';\n\ninterface AuthRequest extends Request {\n  user?: {\n    id: string;\n    email: string;\n  };\n}\n\nexport const authenticateToken = async (\n  req: AuthRequest,\n  res: Response,\n  next: NextFunction\n) => {\n  const authHeader = req.headers.authorization;\n  const token = authHeader && authHeader.split(' ')[1];\n\n  if (!token) {\n    return res.status(401).json({\n      success: false,\n      message: 'Access token required'\n    });\n  }\n\n  try {\n    const decoded = jwt.verify(token, process.env.JWT_SECRET!) as {\n      userId: string;\n      email: string;\n    };\n\n    const user = await prisma.user.findUnique({\n      where: { id: decoded.userId },\n      select: { id: true, email: true }\n    });\n\n    if (!user) {\n      return res.status(401).json({\n        success: false,\n        message: 'Invalid token'\n      });\n    }\n\n    req.user = user;\n    next();\n  } catch (error) {\n    return res.status(403).json({\n      success: false,\n      message: 'Invalid or expired token'\n    });\n  }\n};\n```\n\n### Error Handling Middleware\n```ts\n// src/middleware/errorHandler.ts\nimport { Request, Response, NextFunction } from 'express';\nimport { ZodError } from 'zod';\n\nexport const errorHandler = (\n  error: any,\n  req: Request,\n  res: Response,\n  next: NextFunction\n) => {\n  console.error('Error:', error);\n\n  // Validation errors\n  if (error instanceof ZodError) {\n    return res.status(400).json({\n      success: false,\n      message: 'Validation error',\n      errors: error.errors.map(err => ({\n        field: err.path.join('.'),\n        message: err.message\n      }))\n    });\n  }\n\n  // Database errors\n  if (error.code === 'P2002') {\n    return res.status(409).json({\n      success: false,\n      message: 'Resource already exists'\n    });\n  }\n\n  // Default error\n  res.status(error.statusCode || 500).json({\n    success: false,\n    message: error.message || 'Internal server error',\n    ...(process.env.NODE_ENV === 'development' && { stack: error.stack })\n  });\n};\n```\n\n### Route Definition\n```ts\n// src/routes/users.ts\nimport { Router } from 'express';\nimport { userController } from '../controllers/userController';\nimport { authenticateToken } from '../middleware/auth';\nimport { validateRequest } from '../middleware/validation';\nimport { CreateUserSchema, UpdateUserSchema } from '../types/user';\n\nconst router = Router();\n\nrouter.get('/', userController.getUsers);\nrouter.post('/', validateRequest(CreateUserSchema), userController.createUser);\nrouter.get('/:id', userController.getUserById);\nrouter.put('/:id', authenticateToken, validateRequest(UpdateUserSchema), userController.updateUser);\nrouter.delete('/:id', authenticateToken, userController.deleteUser);\n\nexport default router;\n```\n\n## Testing\n\n- Use Jest for unit and integration tests\n- Test controllers, services, and middleware\n- Use Supertest for API endpoint testing\n- Mock database calls in unit tests\n- Use test database for integration tests\n\n## Database\n\n- Use Prisma ORM for database operations\n- Implement proper database migrations\n- Use database transactions for complex operations\n- Implement proper indexing\n- Use connection pooling\n\n## Deployment\n\n- Use PM2 for process management\n- Set up proper logging with Winston\n- Implement health check endpoints\n- Use environment-specific configurations\n- Set up monitoring and alerting",
      "tags": [
        {
          "tag": {
            "id": "nodejs",
            "name": "nodejs",
            "slug": "nodejs"
          }
        },
        {
          "tag": {
            "id": "express",
            "name": "express",
            "slug": "express"
          }
        },
        {
          "tag": {
            "id": "typescript",
            "name": "typescript",
            "slug": "typescript"
          }
        },
        {
          "tag": {
            "id": "rest-api",
            "name": "rest-api",
            "slug": "rest-api"
          }
        },
        {
          "tag": {
            "id": "backend",
            "name": "backend",
            "slug": "backend"
          }
        }
      ],
      "author": {
        "name": "Claude Code Community",
        "url": "https://github.com/claudecode-community"
      },
      "stats": {
        "votes": 22,
        "copies": 57
      },
      "_count": {
        "votes": 31,
        "copies": 203
      },
      "difficulty": "INTERMEDIATE",
      "language": "TypeScript",
      "framework": "Express.js",
      "lastUpdated": "2024-12-01",
      "featured": false
    },
    {
      "id": "fastapi-python",
      "title": "FastAPI + Python + SQLAlchemy",
      "slug": "fastapi-python-sqlalchemy",
      "tagline": "FastAPI configuration for intermediate developers",
      "description": "High-performance Python API with FastAPI, SQLAlchemy ORM, and modern Python development practices.",
      "categoryId": "claude-configs",
      "category": {
        "id": "claude-configs",
        "name": "Claude.md Configurations",
        "slug": "claude-configs",
        "description": "Ready-to-use Claude.md configuration files for different tech stacks and project types.",
        "icon": "ðŸ“‹",
        "color": "#F59E0B"
      },
      "type": "CONFIGURATION",
      "content": "# Claude.md - FastAPI + Python + SQLAlchemy API\n\n## Project Overview\n\nThis is a high-performance Python API built with FastAPI, SQLAlchemy ORM, and Pydantic for data validation, following modern Python development practices.\n\n## Technology Stack\n\n- **Framework**: FastAPI\n- **Language**: Python 3.11+\n- **ORM**: SQLAlchemy 2.0 with async support\n- **Validation**: Pydantic V2\n- **Database**: PostgreSQL\n- **Authentication**: OAuth2 with JWT\n- **Testing**: Pytest with async support\n- **Documentation**: Auto-generated OpenAPI/Swagger\n\n## Project Structure\n\n```\napp/\nâ”œâ”€â”€ api/               # API routes\nâ”‚   â”œâ”€â”€ v1/           # API version 1\nâ”‚   â””â”€â”€ dependencies.py # Route dependencies\nâ”œâ”€â”€ core/             # Core configuration\nâ”œâ”€â”€ crud/             # Database operations\nâ”œâ”€â”€ db/               # Database setup\nâ”œâ”€â”€ models/           # SQLAlchemy models\nâ”œâ”€â”€ schemas/          # Pydantic schemas\nâ”œâ”€â”€ services/         # Business logic\nâ”œâ”€â”€ utils/            # Utility functions\nâ””â”€â”€ main.py          # FastAPI app setup\n```\n\n## Development Guidelines\n\n### Code Style\n- Follow PEP 8 style guide\n- Use type hints throughout\n- Use async/await for I/O operations\n- Follow REST API conventions\n- Use Pydantic for data validation\n\n### API Design\n- Use automatic API documentation\n- Implement proper HTTP status codes\n- Use dependency injection\n- Implement proper error handling\n- Use background tasks for long operations\n\n### Performance\n- Use async database operations\n- Implement connection pooling\n- Use caching where appropriate\n- Optimize database queries\n- Use pagination for large datasets\n\n## Key Commands\n\n- `uvicorn app.main:app --reload` - Start development server\n- `pytest` - Run tests\n- `black .` - Format code\n- `mypy .` - Type checking\n- `flake8 .` - Linting\n\n## Environment Variables\n\nCreate a `.env` file:\n```\nDATABASE_URL=postgresql+asyncpg://user:password@localhost/dbname\nSECRET_KEY=your-super-secret-key\nALGORITHM=HS256\nACCESS_TOKEN_EXPIRE_MINUTES=30\nENVIRONMENT=development\n```\n\n## Common Patterns\n\n### FastAPI App Setup\n```python\n# app/main.py\nfrom fastapi import FastAPI, Request\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom contextlib import asynccontextmanager\n\nfrom app.api.v1.api import api_router\nfrom app.core.config import settings\nfrom app.db.init_db import init_db\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Startup\n    await init_db()\n    yield\n    # Shutdown\n    pass\n\n\napp = FastAPI(\n    title=settings.PROJECT_NAME,\n    openapi_url=f\"{settings.API_V1_STR}/openapi.json\",\n    lifespan=lifespan\n)\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=settings.BACKEND_CORS_ORIGINS,\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\napp.include_router(api_router, prefix=settings.API_V1_STR)\n\n\n@app.get(\"/\")\nasync def root():\n    return {\"message\": \"Hello World\"}\n\n\n@app.get(\"/health\")\nasync def health_check():\n    return {\"status\": \"healthy\"}\n```\n\n### Pydantic Schemas\n```python\n# app/schemas/user.py\nfrom pydantic import BaseModel, EmailStr, Field\nfrom datetime import datetime\nfrom typing import Optional\n\n\nclass UserBase(BaseModel):\n    email: EmailStr\n    name: str = Field(..., min_length=1, max_length=100)\n    is_active: bool = True\n\n\nclass UserCreate(UserBase):\n    password: str = Field(..., min_length=8)\n\n\nclass UserUpdate(BaseModel):\n    email: Optional[EmailStr] = None\n    name: Optional[str] = Field(None, min_length=1, max_length=100)\n    is_active: Optional[bool] = None\n\n\nclass UserInDBBase(UserBase):\n    id: int\n    created_at: datetime\n    updated_at: datetime\n\n    class Config:\n        from_attributes = True\n\n\nclass User(UserInDBBase):\n    pass\n\n\nclass UserInDB(UserInDBBase):\n    hashed_password: str\n```\n\n### SQLAlchemy Models\n```python\n# app/models/user.py\nfrom sqlalchemy import Boolean, Column, Integer, String, DateTime\nfrom sqlalchemy.sql import func\nfrom app.db.base_class import Base\n\n\nclass User(Base):\n    id = Column(Integer, primary_key=True, index=True)\n    email = Column(String, unique=True, index=True, nullable=False)\n    name = Column(String, nullable=False)\n    hashed_password = Column(String, nullable=False)\n    is_active = Column(Boolean, default=True)\n    created_at = Column(DateTime(timezone=True), server_default=func.now())\n    updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n```\n\n### CRUD Operations\n```python\n# app/crud/user.py\nfrom typing import List, Optional\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy import select\nfrom app.crud.base import CRUDBase\nfrom app.models.user import User\nfrom app.schemas.user import UserCreate, UserUpdate\nfrom app.core.security import get_password_hash, verify_password\n\n\nclass CRUDUser(CRUDBase[User, UserCreate, UserUpdate]):\n    async def get_by_email(\n        self, db: AsyncSession, *, email: str\n    ) -> Optional[User]:\n        result = await db.execute(select(User).where(User.email == email))\n        return result.scalar_one_or_none()\n\n    async def create(self, db: AsyncSession, *, obj_in: UserCreate) -> User:\n        hashed_password = get_password_hash(obj_in.password)\n        db_obj = User(\n            email=obj_in.email,\n            name=obj_in.name,\n            hashed_password=hashed_password,\n            is_active=obj_in.is_active,\n        )\n        db.add(db_obj)\n        await db.commit()\n        await db.refresh(db_obj)\n        return db_obj\n\n    async def authenticate(\n        self, db: AsyncSession, *, email: str, password: str\n    ) -> Optional[User]:\n        user = await self.get_by_email(db, email=email)\n        if not user:\n            return None\n        if not verify_password(password, user.hashed_password):\n            return None\n        return user\n\n    async def is_active(self, user: User) -> bool:\n        return user.is_active\n\n\nuser = CRUDUser(User)\n```\n\n### API Routes\n```python\n# app/api/v1/endpoints/users.py\nfrom typing import List\nfrom fastapi import APIRouter, Depends, HTTPException, status\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.api import dependencies\nfrom app.crud import user as crud_user\nfrom app.schemas.user import User, UserCreate, UserUpdate\nfrom app.models.user import User as UserModel\n\nrouter = APIRouter()\n\n\n@router.get(\"/\", response_model=List[User])\nasync def read_users(\n    skip: int = 0,\n    limit: int = 100,\n    db: AsyncSession = Depends(dependencies.get_db),\n    current_user: UserModel = Depends(dependencies.get_current_active_user),\n):\n    \"\"\"\n    Retrieve users.\n    \"\"\"\n    users = await crud_user.user.get_multi(db, skip=skip, limit=limit)\n    return users\n\n\n@router.post(\"/\", response_model=User, status_code=status.HTTP_201_CREATED)\nasync def create_user(\n    *,\n    db: AsyncSession = Depends(dependencies.get_db),\n    user_in: UserCreate,\n):\n    \"\"\"\n    Create new user.\n    \"\"\"\n    user = await crud_user.user.get_by_email(db, email=user_in.email)\n    if user:\n        raise HTTPException(\n            status_code=400,\n            detail=\"User with this email already exists\",\n        )\n    user = await crud_user.user.create(db, obj_in=user_in)\n    return user\n\n\n@router.get(\"/{user_id}\", response_model=User)\nasync def read_user(\n    user_id: int,\n    db: AsyncSession = Depends(dependencies.get_db),\n    current_user: UserModel = Depends(dependencies.get_current_active_user),\n):\n    \"\"\"\n    Get user by ID.\n    \"\"\"\n    user = await crud_user.user.get(db, id=user_id)\n    if not user:\n        raise HTTPException(\n            status_code=404,\n            detail=\"User not found\",\n        )\n    return user\n```\n\n### Authentication Dependencies\n```python\n# app/api/dependencies.py\nfrom typing import AsyncGenerator\nfrom fastapi import Depends, HTTPException, status\nfrom fastapi.security import OAuth2PasswordBearer\nfrom jose import JWTError, jwt\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.core import security\nfrom app.core.config import settings\nfrom app.crud import user as crud_user\nfrom app.db.session import async_session\nfrom app.models.user import User\n\noauth2_scheme = OAuth2PasswordBearer(\n    tokenUrl=f\"{settings.API_V1_STR}/auth/login\"\n)\n\n\nasync def get_db() -> AsyncGenerator[AsyncSession, None]:\n    async with async_session() as session:\n        yield session\n\n\nasync def get_current_user(\n    db: AsyncSession = Depends(get_db),\n    token: str = Depends(oauth2_scheme),\n) -> User:\n    credentials_exception = HTTPException(\n        status_code=status.HTTP_401_UNAUTHORIZED,\n        detail=\"Could not validate credentials\",\n        headers={\"WWW-Authenticate\": \"Bearer\"},\n    )\n    \n    try:\n        payload = jwt.decode(\n            token, settings.SECRET_KEY, algorithms=[settings.ALGORITHM]\n        )\n        user_id: int = payload.get(\"sub\")\n        if user_id is None:\n            raise credentials_exception\n    except JWTError:\n        raise credentials_exception\n    \n    user = await crud_user.user.get(db, id=user_id)\n    if user is None:\n        raise credentials_exception\n    return user\n\n\nasync def get_current_active_user(\n    current_user: User = Depends(get_current_user),\n) -> User:\n    if not crud_user.user.is_active(current_user):\n        raise HTTPException(\n            status_code=400, \n            detail=\"Inactive user\"\n        )\n    return current_user\n```\n\n### Background Tasks\n```python\n# app/services/email.py\nfrom fastapi import BackgroundTasks\nimport smtplib\nfrom email.mime.text import MIMEText\n\n\ndef send_email_background(\n    background_tasks: BackgroundTasks,\n    email: str,\n    subject: str,\n    body: str,\n):\n    background_tasks.add_task(send_email, email, subject, body)\n\n\ndef send_email(email: str, subject: str, body: str):\n    # Email sending logic\n    msg = MIMEText(body)\n    msg['Subject'] = subject\n    msg['From'] = 'noreply@example.com'\n    msg['To'] = email\n    \n    # Send email using SMTP\n    with smtplib.SMTP('localhost') as server:\n        server.send_message(msg)\n```\n\n## Testing\n\n- Use pytest with async support\n- Test API endpoints with TestClient\n- Use database fixtures for testing\n- Mock external dependencies\n- Test both success and error scenarios\n\n## Database\n\n- Use async SQLAlchemy for better performance\n- Implement proper database migrations with Alembic\n- Use connection pooling\n- Implement proper indexing\n- Handle database transactions properly\n\n## Deployment\n\n- Use Docker for containerization\n- Deploy with Gunicorn + Uvicorn workers\n- Set up proper logging\n- Implement health checks\n- Use environment-specific settings",
      "tags": [
        {
          "tag": {
            "id": "python",
            "name": "python",
            "slug": "python"
          }
        },
        {
          "tag": {
            "id": "fastapi",
            "name": "fastapi",
            "slug": "fastapi"
          }
        },
        {
          "tag": {
            "id": "sqlalchemy",
            "name": "sqlalchemy",
            "slug": "sqlalchemy"
          }
        },
        {
          "tag": {
            "id": "pydantic",
            "name": "pydantic",
            "slug": "pydantic"
          }
        },
        {
          "tag": {
            "id": "async",
            "name": "async",
            "slug": "async"
          }
        }
      ],
      "author": {
        "name": "Claude Code Community",
        "url": "https://github.com/claudecode-community"
      },
      "stats": {
        "votes": 51,
        "copies": 130
      },
      "_count": {
        "votes": 51,
        "copies": 243
      },
      "difficulty": "INTERMEDIATE",
      "language": "Python",
      "framework": "FastAPI",
      "lastUpdated": "2024-12-01",
      "featured": false
    },
    {
      "id": "go-gin-api",
      "title": "Go + Gin Framework + GORM",
      "slug": "go-gin-framework-gorm",
      "tagline": "Gin configuration for intermediate developers",
      "description": "Efficient Go REST API with Gin framework, GORM ORM, and Go best practices for high-performance backends.",
      "categoryId": "claude-configs",
      "category": {
        "id": "claude-configs",
        "name": "Claude.md Configurations",
        "slug": "claude-configs",
        "description": "Ready-to-use Claude.md configuration files for different tech stacks and project types.",
        "icon": "ðŸ“‹",
        "color": "#F59E0B"
      },
      "type": "CONFIGURATION",
      "content": "# Claude.md - Go + Gin Framework + GORM API\n\n## Project Overview\n\nThis is a high-performance REST API built with Go, Gin framework, and GORM ORM, following Go best practices for scalable backend development.\n\n## Technology Stack\n\n- **Language**: Go 1.21+\n- **Framework**: Gin Web Framework\n- **ORM**: GORM\n- **Database**: PostgreSQL\n- **Authentication**: JWT\n- **Validation**: go-playground/validator\n- **Testing**: Go built-in testing + testify\n- **Documentation**: Swagger with gin-swagger\n\n## Project Structure\n\n```\nâ”œâ”€â”€ cmd/\nâ”‚   â””â”€â”€ server/\nâ”‚       â””â”€â”€ main.go      # Application entry point\nâ”œâ”€â”€ internal/\nâ”‚   â”œâ”€â”€ config/          # Configuration\nâ”‚   â”œâ”€â”€ controllers/     # HTTP handlers\nâ”‚   â”œâ”€â”€ middleware/      # HTTP middleware\nâ”‚   â”œâ”€â”€ models/          # Database models\nâ”‚   â”œâ”€â”€ repositories/    # Data access layer\nâ”‚   â”œâ”€â”€ services/        # Business logic\nâ”‚   â””â”€â”€ utils/           # Utility functions\nâ”œâ”€â”€ pkg/\nâ”‚   â”œâ”€â”€ database/        # Database connection\nâ”‚   â”œâ”€â”€ logger/          # Logging utilities\nâ”‚   â””â”€â”€ validator/       # Custom validators\nâ””â”€â”€ docs/               # Swagger documentation\n```\n\n## Development Guidelines\n\n### Code Style\n- Follow Go conventions and gofmt\n- Use meaningful package names\n- Implement proper error handling\n- Use interfaces for abstraction\n- Follow the single responsibility principle\n\n### API Design\n- Use RESTful endpoints\n- Implement proper HTTP status codes\n- Use middleware for cross-cutting concerns\n- Implement request validation\n- Use structured logging\n\n### Performance\n- Use connection pooling\n- Implement proper caching\n- Use goroutines for concurrent operations\n- Optimize database queries\n- Use profiling for optimization\n\n## Key Commands\n\n- `go run cmd/server/main.go` - Start development server\n- `go build -o bin/server cmd/server/main.go` - Build binary\n- `go test ./...` - Run tests\n- `go mod tidy` - Clean up dependencies\n- `swag init` - Generate Swagger docs\n\n## Environment Variables\n\nCreate a `.env` file:\n```\nPORT=8080\nDB_HOST=localhost\nDB_PORT=5432\nDB_USER=user\nDB_PASSWORD=password\nDB_NAME=dbname\nJWT_SECRET=your-jwt-secret\nGIN_MODE=debug\nLOG_LEVEL=info\n```\n\n## Common Patterns\n\n### Main Application Setup\n```go\n// cmd/server/main.go\npackage main\n\nimport (\n    \"log\"\n    \"os\"\n\n    \"github.com/joho/godotenv\"\n    \"your-app/internal/config\"\n    \"your-app/internal/controllers\"\n    \"your-app/internal/middleware\"\n    \"your-app/pkg/database\"\n    \"your-app/pkg/logger\"\n    \n    \"github.com/gin-gonic/gin\"\n    swaggerFiles \"github.com/swaggo/files\"\n    ginSwagger \"github.com/swaggo/gin-swagger\"\n)\n\nfunc main() {\n    // Load environment variables\n    if err := godotenv.Load(); err != nil {\n        log.Println(\"No .env file found\")\n    }\n\n    // Initialize config\n    cfg := config.Load()\n\n    // Initialize logger\n    logger.Init(cfg.LogLevel)\n\n    // Initialize database\n    db, err := database.Connect(cfg.DatabaseURL)\n    if err != nil {\n        log.Fatal(\"Failed to connect to database:\", err)\n    }\n\n    // Auto-migrate models\n    database.Migrate(db)\n\n    // Initialize Gin router\n    if cfg.Environment == \"production\" {\n        gin.SetMode(gin.ReleaseMode)\n    }\n\n    router := gin.New()\n    router.Use(gin.Logger())\n    router.Use(gin.Recovery())\n    router.Use(middleware.CORS())\n\n    // Initialize controllers\n    userController := controllers.NewUserController(db)\n    authController := controllers.NewAuthController(db)\n\n    // Routes\n    v1 := router.Group(\"/api/v1\")\n    {\n        auth := v1.Group(\"/auth\")\n        {\n            auth.POST(\"/login\", authController.Login)\n            auth.POST(\"/register\", authController.Register)\n        }\n\n        users := v1.Group(\"/users\")\n        users.Use(middleware.AuthRequired())\n        {\n            users.GET(\"\", userController.GetUsers)\n            users.GET(\"/:id\", userController.GetUser)\n            users.PUT(\"/:id\", userController.UpdateUser)\n            users.DELETE(\"/:id\", userController.DeleteUser)\n        }\n    }\n\n    // Swagger documentation\n    router.GET(\"/swagger/*any\", ginSwagger.WrapHandler(swaggerFiles.Handler))\n\n    // Health check\n    router.GET(\"/health\", func(c *gin.Context) {\n        c.JSON(200, gin.H{\"status\": \"healthy\"})\n    })\n\n    // Start server\n    port := os.Getenv(\"PORT\")\n    if port == \"\" {\n        port = \"8080\"\n    }\n\n    log.Printf(\"Server starting on port %s\", port)\n    if err := router.Run(\":\" + port); err != nil {\n        log.Fatal(\"Failed to start server:\", err)\n    }\n}\n```\n\n### Database Models\n```go\n// internal/models/user.go\npackage models\n\nimport (\n    \"time\"\n    \"gorm.io/gorm\"\n)\n\ntype User struct {\n    ID        uint           `json:\"id\" gorm:\"primaryKey\"`\n    Name      string         `json:\"name\" gorm:\"not null\" validate:\"required,min=1,max=100\"`\n    Email     string         `json:\"email\" gorm:\"uniqueIndex;not null\" validate:\"required,email\"`\n    Password  string         `json:\"-\" gorm:\"not null\" validate:\"required,min=8\"`\n    IsActive  bool           `json:\"is_active\" gorm:\"default:true\"`\n    CreatedAt time.Time      `json:\"created_at\"`\n    UpdatedAt time.Time      `json:\"updated_at\"`\n    DeletedAt gorm.DeletedAt `json:\"-\" gorm:\"index\"`\n}\n\ntype CreateUserRequest struct {\n    Name     string `json:\"name\" validate:\"required,min=1,max=100\"`\n    Email    string `json:\"email\" validate:\"required,email\"`\n    Password string `json:\"password\" validate:\"required,min=8\"`\n}\n\ntype UpdateUserRequest struct {\n    Name     *string `json:\"name,omitempty\" validate:\"omitempty,min=1,max=100\"`\n    Email    *string `json:\"email,omitempty\" validate:\"omitempty,email\"`\n    IsActive *bool   `json:\"is_active,omitempty\"`\n}\n\ntype UserResponse struct {\n    ID        uint      `json:\"id\"`\n    Name      string    `json:\"name\"`\n    Email     string    `json:\"email\"`\n    IsActive  bool      `json:\"is_active\"`\n    CreatedAt time.Time `json:\"created_at\"`\n    UpdatedAt time.Time `json:\"updated_at\"`\n}\n\nfunc (u *User) ToResponse() UserResponse {\n    return UserResponse{\n        ID:        u.ID,\n        Name:      u.Name,\n        Email:     u.Email,\n        IsActive:  u.IsActive,\n        CreatedAt: u.CreatedAt,\n        UpdatedAt: u.UpdatedAt,\n    }\n}\n```\n\n### Repository Pattern\n```go\n// internal/repositories/user_repository.go\npackage repositories\n\nimport (\n    \"your-app/internal/models\"\n    \"gorm.io/gorm\"\n)\n\ntype UserRepository interface {\n    Create(user *models.User) error\n    GetByID(id uint) (*models.User, error)\n    GetByEmail(email string) (*models.User, error)\n    GetAll(offset, limit int) ([]models.User, error)\n    Update(user *models.User) error\n    Delete(id uint) error\n    Count() (int64, error)\n}\n\ntype userRepository struct {\n    db *gorm.DB\n}\n\nfunc NewUserRepository(db *gorm.DB) UserRepository {\n    return &userRepository{db: db}\n}\n\nfunc (r *userRepository) Create(user *models.User) error {\n    return r.db.Create(user).Error\n}\n\nfunc (r *userRepository) GetByID(id uint) (*models.User, error) {\n    var user models.User\n    err := r.db.First(&user, id).Error\n    if err != nil {\n        return nil, err\n    }\n    return &user, nil\n}\n\nfunc (r *userRepository) GetByEmail(email string) (*models.User, error) {\n    var user models.User\n    err := r.db.Where(\"email = ?\", email).First(&user).Error\n    if err != nil {\n        return nil, err\n    }\n    return &user, nil\n}\n\nfunc (r *userRepository) GetAll(offset, limit int) ([]models.User, error) {\n    var users []models.User\n    err := r.db.Offset(offset).Limit(limit).Find(&users).Error\n    return users, err\n}\n\nfunc (r *userRepository) Update(user *models.User) error {\n    return r.db.Save(user).Error\n}\n\nfunc (r *userRepository) Delete(id uint) error {\n    return r.db.Delete(&models.User{}, id).Error\n}\n\nfunc (r *userRepository) Count() (int64, error) {\n    var count int64\n    err := r.db.Model(&models.User{}).Count(&count).Error\n    return count, err\n}\n```\n\n### Service Layer\n```go\n// internal/services/user_service.go\npackage services\n\nimport (\n    \"errors\"\n    \"your-app/internal/models\"\n    \"your-app/internal/repositories\"\n    \"your-app/pkg/utils\"\n    \n    \"golang.org/x/crypto/bcrypt\"\n    \"gorm.io/gorm\"\n)\n\ntype UserService interface {\n    CreateUser(req *models.CreateUserRequest) (*models.User, error)\n    GetUser(id uint) (*models.User, error)\n    GetUsers(page, limit int) ([]models.User, int64, error)\n    UpdateUser(id uint, req *models.UpdateUserRequest) (*models.User, error)\n    DeleteUser(id uint) error\n    AuthenticateUser(email, password string) (*models.User, error)\n}\n\ntype userService struct {\n    userRepo repositories.UserRepository\n}\n\nfunc NewUserService(userRepo repositories.UserRepository) UserService {\n    return &userService{\n        userRepo: userRepo,\n    }\n}\n\nfunc (s *userService) CreateUser(req *models.CreateUserRequest) (*models.User, error) {\n    // Check if user already exists\n    existingUser, err := s.userRepo.GetByEmail(req.Email)\n    if err == nil && existingUser != nil {\n        return nil, errors.New(\"user with this email already exists\")\n    }\n\n    // Hash password\n    hashedPassword, err := bcrypt.GenerateFromPassword([]byte(req.Password), bcrypt.DefaultCost)\n    if err != nil {\n        return nil, err\n    }\n\n    user := &models.User{\n        Name:     req.Name,\n        Email:    req.Email,\n        Password: string(hashedPassword),\n        IsActive: true,\n    }\n\n    err = s.userRepo.Create(user)\n    if err != nil {\n        return nil, err\n    }\n\n    return user, nil\n}\n\nfunc (s *userService) GetUser(id uint) (*models.User, error) {\n    return s.userRepo.GetByID(id)\n}\n\nfunc (s *userService) GetUsers(page, limit int) ([]models.User, int64, error) {\n    offset := (page - 1) * limit\n    users, err := s.userRepo.GetAll(offset, limit)\n    if err != nil {\n        return nil, 0, err\n    }\n\n    total, err := s.userRepo.Count()\n    if err != nil {\n        return nil, 0, err\n    }\n\n    return users, total, nil\n}\n\nfunc (s *userService) AuthenticateUser(email, password string) (*models.User, error) {\n    user, err := s.userRepo.GetByEmail(email)\n    if err != nil {\n        if errors.Is(err, gorm.ErrRecordNotFound) {\n            return nil, errors.New(\"invalid credentials\")\n        }\n        return nil, err\n    }\n\n    err = bcrypt.CompareHashAndPassword([]byte(user.Password), []byte(password))\n    if err != nil {\n        return nil, errors.New(\"invalid credentials\")\n    }\n\n    if !user.IsActive {\n        return nil, errors.New(\"account is deactivated\")\n    }\n\n    return user, nil\n}\n```\n\n### HTTP Controllers\n```go\n// internal/controllers/user_controller.go\npackage controllers\n\nimport (\n    \"net/http\"\n    \"strconv\"\n\n    \"your-app/internal/models\"\n    \"your-app/internal/services\"\n    \"your-app/pkg/utils\"\n\n    \"github.com/gin-gonic/gin\"\n    \"github.com/go-playground/validator/v10\"\n)\n\ntype UserController struct {\n    userService services.UserService\n    validator   *validator.Validate\n}\n\nfunc NewUserController(userService services.UserService) *UserController {\n    return &UserController{\n        userService: userService,\n        validator:   validator.New(),\n    }\n}\n\n// GetUsers godoc\n// @Summary Get users\n// @Description Get list of users with pagination\n// @Tags users\n// @Accept json\n// @Produce json\n// @Param page query int false \"Page number\" default(1)\n// @Param limit query int false \"Items per page\" default(10)\n// @Success 200 {object} utils.PaginatedResponse\n// @Failure 400 {object} utils.ErrorResponse\n// @Router /users [get]\nfunc (c *UserController) GetUsers(ctx *gin.Context) {\n    page, _ := strconv.Atoi(ctx.DefaultQuery(\"page\", \"1\"))\n    limit, _ := strconv.Atoi(ctx.DefaultQuery(\"limit\", \"10\"))\n\n    if page < 1 {\n        page = 1\n    }\n    if limit < 1 || limit > 100 {\n        limit = 10\n    }\n\n    users, total, err := c.userService.GetUsers(page, limit)\n    if err != nil {\n        utils.ErrorResponse(ctx, http.StatusInternalServerError, \"Failed to get users\", err)\n        return\n    }\n\n    var userResponses []models.UserResponse\n    for _, user := range users {\n        userResponses = append(userResponses, user.ToResponse())\n    }\n\n    utils.PaginatedResponse(ctx, userResponses, page, limit, total)\n}\n\n// CreateUser godoc\n// @Summary Create user\n// @Description Create a new user\n// @Tags users\n// @Accept json\n// @Produce json\n// @Param user body models.CreateUserRequest true \"User data\"\n// @Success 201 {object} models.UserResponse\n// @Failure 400 {object} utils.ErrorResponse\n// @Router /users [post]\nfunc (c *UserController) CreateUser(ctx *gin.Context) {\n    var req models.CreateUserRequest\n    if err := ctx.ShouldBindJSON(&req); err != nil {\n        utils.ValidationErrorResponse(ctx, err)\n        return\n    }\n\n    if err := c.validator.Struct(&req); err != nil {\n        utils.ValidationErrorResponse(ctx, err)\n        return\n    }\n\n    user, err := c.userService.CreateUser(&req)\n    if err != nil {\n        utils.ErrorResponse(ctx, http.StatusBadRequest, \"Failed to create user\", err)\n        return\n    }\n\n    ctx.JSON(http.StatusCreated, user.ToResponse())\n}\n```\n\n### Authentication Middleware\n```go\n// internal/middleware/auth.go\npackage middleware\n\nimport (\n    \"net/http\"\n    \"strings\"\n\n    \"your-app/pkg/utils\"\n\n    \"github.com/gin-gonic/gin\"\n    \"github.com/golang-jwt/jwt/v4\"\n)\n\nfunc AuthRequired() gin.HandlerFunc {\n    return func(c *gin.Context) {\n        tokenString := c.GetHeader(\"Authorization\")\n        if tokenString == \"\" {\n            utils.ErrorResponse(c, http.StatusUnauthorized, \"Authorization header required\", nil)\n            c.Abort()\n            return\n        }\n\n        // Remove \"Bearer \" prefix\n        tokenString = strings.TrimPrefix(tokenString, \"Bearer \")\n\n        token, err := jwt.Parse(tokenString, func(token *jwt.Token) (interface{}, error) {\n            return []byte(utils.GetEnv(\"JWT_SECRET\", \"secret\")), nil\n        })\n\n        if err != nil || !token.Valid {\n            utils.ErrorResponse(c, http.StatusUnauthorized, \"Invalid token\", err)\n            c.Abort()\n            return\n        }\n\n        if claims, ok := token.Claims.(jwt.MapClaims); ok {\n            c.Set(\"user_id\", claims[\"user_id\"])\n            c.Set(\"email\", claims[\"email\"])\n        }\n\n        c.Next()\n    }\n}\n```\n\n## Testing\n\n- Use Go's built-in testing package\n- Write unit tests for services and repositories\n- Use testify for assertions\n- Mock dependencies with interfaces\n- Write integration tests for controllers\n\n## Database\n\n- Use GORM for ORM operations\n- Implement database migrations\n- Use connection pooling\n- Implement proper indexing\n- Handle transactions properly\n\n## Deployment\n\n- Build static binary with Go\n- Use Docker for containerization\n- Deploy with proper environment configuration\n- Set up health checks and monitoring\n- Use graceful shutdown",
      "tags": [
        {
          "tag": {
            "id": "go",
            "name": "go",
            "slug": "go"
          }
        },
        {
          "tag": {
            "id": "gin",
            "name": "gin",
            "slug": "gin"
          }
        },
        {
          "tag": {
            "id": "gorm",
            "name": "gorm",
            "slug": "gorm"
          }
        },
        {
          "tag": {
            "id": "rest-api",
            "name": "rest-api",
            "slug": "rest-api"
          }
        },
        {
          "tag": {
            "id": "golang",
            "name": "golang",
            "slug": "golang"
          }
        }
      ],
      "author": {
        "name": "Claude Code Community",
        "url": "https://github.com/claudecode-community"
      },
      "stats": {
        "votes": 13,
        "copies": 167
      },
      "_count": {
        "votes": 11,
        "copies": 151
      },
      "difficulty": "INTERMEDIATE",
      "language": "Go",
      "framework": "Gin",
      "lastUpdated": "2024-12-01",
      "featured": false
    },
    {
      "id": "ruby-rails-api",
      "title": "Ruby on Rails API + ActiveRecord",
      "slug": "ruby-rails-api-activerecord",
      "tagline": "Ruby on Rails configuration for intermediate developers",
      "description": "Ruby on Rails API application with ActiveRecord, modern Rails patterns, and comprehensive backend features.",
      "categoryId": "claude-configs",
      "category": {
        "id": "claude-configs",
        "name": "Claude.md Configurations",
        "slug": "claude-configs",
        "description": "Ready-to-use Claude.md configuration files for different tech stacks and project types.",
        "icon": "ðŸ“‹",
        "color": "#F59E0B"
      },
      "type": "CONFIGURATION",
      "content": "# Claude.md - Ruby on Rails API + ActiveRecord\n\n## Project Overview\n\nThis is a Ruby on Rails API application using ActiveRecord ORM, following Rails conventions and modern Ruby development practices for scalable backend systems.\n\n## Technology Stack\n\n- **Language**: Ruby 3.2+\n- **Framework**: Ruby on Rails 7.1+\n- **ORM**: ActiveRecord\n- **Database**: PostgreSQL\n- **Authentication**: JWT with Devise\n- **Testing**: RSpec with FactoryBot\n- **Documentation**: RSwag for API docs\n- **Background Jobs**: Sidekiq\n\n## Project Structure\n\n```\napp/\nâ”œâ”€â”€ controllers/         # API controllers\nâ”‚   â””â”€â”€ api/\nâ”‚       â””â”€â”€ v1/         # API version 1\nâ”œâ”€â”€ models/             # ActiveRecord models\nâ”œâ”€â”€ serializers/        # JSON serializers\nâ”œâ”€â”€ services/           # Business logic services\nâ”œâ”€â”€ jobs/               # Background jobs\nâ””â”€â”€ lib/                # Custom libraries\nconfig/\nâ”œâ”€â”€ routes.rb           # Route definitions\nâ”œâ”€â”€ database.yml        # Database configuration\nâ””â”€â”€ application.rb      # Application configuration\ndb/\nâ”œâ”€â”€ migrate/            # Database migrations\nâ””â”€â”€ seeds.rb           # Database seeds\nspec/                  # RSpec tests\n```\n\n## Development Guidelines\n\n### Code Style\n- Follow Ruby style guide and Rails conventions\n- Use Rubocop for code formatting\n- Implement proper error handling\n- Use ActiveRecord validations\n- Follow RESTful resource patterns\n\n### API Design\n- Use Rails API mode\n- Implement proper serialization\n- Use consistent error responses\n- Implement pagination with Kaminari\n- Follow JSON API standards\n\n### Performance\n- Use database indexing\n- Implement eager loading to avoid N+1 queries\n- Use caching with Redis\n- Implement background jobs for heavy tasks\n- Use database connection pooling\n\n## Key Commands\n\n- `rails server` - Start development server\n- `rails console` - Open Rails console\n- `rails generate` - Generate Rails components\n- `rails db:migrate` - Run database migrations\n- `rspec` - Run tests\n- `rubocop` - Run code linting\n\n## Environment Variables\n\nCreate a `.env` file:\n```\nDATABASE_URL=postgresql://user:password@localhost/myapp_development\nREDIS_URL=redis://localhost:6379/0\nJWT_SECRET=your-jwt-secret-key\nRAILS_ENV=development\nSECRET_KEY_BASE=your-secret-key-base\n```\n\n## Common Patterns\n\n### Rails Application Configuration\n```ruby\n# config/application.rb\nrequire_relative \"boot\"\nrequire \"rails\"\n\n# Pick the frameworks you want:\nrequire \"active_model/railtie\"\nrequire \"active_job/railtie\"\nrequire \"active_record/railtie\"\nrequire \"active_storage/engine\"\nrequire \"action_controller/railtie\"\nrequire \"action_mailer/railtie\"\nrequire \"action_mailbox/engine\"\nrequire \"action_text/engine\"\nrequire \"action_view/railtie\"\nrequire \"action_cable/engine\"\n\nBundler.require(*Rails.groups)\n\nmodule MyApp\n  class Application < Rails::Application\n    config.load_defaults 7.1\n\n    # API-only application\n    config.api_only = true\n\n    # CORS configuration\n    config.middleware.insert_before 0, Rack::Cors do\n      allow do\n        origins '*'\n        resource '*',\n                 headers: :any,\n                 methods: [:get, :post, :put, :patch, :delete, :options, :head],\n                 credentials: false\n      end\n    end\n\n    # Timezone\n    config.time_zone = 'UTC'\n\n    # Autoload paths\n    config.autoload_paths += %W(#{config.root}/lib)\n\n    # Active Job queue adapter\n    config.active_job.queue_adapter = :sidekiq\n  end\nend\n```\n\n### ActiveRecord Models\n```ruby\n# app/models/user.rb\nclass User < ApplicationRecord\n  has_secure_password\n\n  has_many :posts, dependent: :destroy\n  has_many :comments, dependent: :destroy\n\n  validates :name, presence: true, length: { minimum: 1, maximum: 100 }\n  validates :email, presence: true, uniqueness: { case_sensitive: false },\n            format: { with: URI::MailTo::EMAIL_REGEXP }\n  validates :password, length: { minimum: 8 }, allow_nil: true\n\n  scope :active, -> { where(is_active: true) }\n  scope :by_name, ->(name) { where('name ILIKE ?', \"%#{name}%\") }\n\n  before_save :downcase_email\n\n  def full_name\n    \"#{first_name} #{last_name}\".strip\n  end\n\n  def active?\n    is_active\n  end\n\n  private\n\n  def downcase_email\n    self.email = email.downcase if email.present?\n  end\nend\n\n# app/models/post.rb\nclass Post < ApplicationRecord\n  belongs_to :user\n  has_many :comments, dependent: :destroy\n\n  validates :title, presence: true, length: { maximum: 255 }\n  validates :content, presence: true\n  validates :status, inclusion: { in: %w[draft published archived] }\n\n  scope :published, -> { where(status: 'published') }\n  scope :by_user, ->(user) { where(user: user) }\n  scope :recent, -> { order(created_at: :desc) }\n\n  enum status: { draft: 0, published: 1, archived: 2 }\n\n  def published?\n    status == 'published'\n  end\nend\n```\n\n### API Controllers\n```ruby\n# app/controllers/application_controller.rb\nclass ApplicationController < ActionController::API\n  include ActionController::HttpAuthentication::Token::ControllerMethods\n\n  before_action :authenticate_user!\n\n  rescue_from ActiveRecord::RecordNotFound, with: :record_not_found\n  rescue_from ActiveRecord::RecordInvalid, with: :record_invalid\n  rescue_from ActionController::ParameterMissing, with: :parameter_missing\n\n  private\n\n  def authenticate_user!\n    token = request.headers['Authorization']&.split(' ')&.last\n    \n    if token.blank?\n      render json: { error: 'Authorization token required' }, status: :unauthorized\n      return\n    end\n\n    begin\n      decoded_token = JWT.decode(token, Rails.application.secret_key_base, true, algorithm: 'HS256')\n      user_id = decoded_token[0]['user_id']\n      @current_user = User.find(user_id)\n    rescue JWT::DecodeError, JWT::ExpiredSignature, ActiveRecord::RecordNotFound\n      render json: { error: 'Invalid or expired token' }, status: :unauthorized\n    end\n  end\n\n  def current_user\n    @current_user\n  end\n\n  def record_not_found(exception)\n    render json: { error: 'Record not found' }, status: :not_found\n  end\n\n  def record_invalid(exception)\n    render json: { \n      error: 'Validation failed', \n      details: exception.record.errors.full_messages \n    }, status: :unprocessable_entity\n  end\n\n  def parameter_missing(exception)\n    render json: { error: exception.message }, status: :bad_request\n  end\nend\n\n# app/controllers/api/v1/users_controller.rb\nclass Api::V1::UsersController < ApplicationController\n  before_action :set_user, only: [:show, :update, :destroy]\n\n  # GET /api/v1/users\n  def index\n    @users = User.active\n    @users = @users.by_name(params[:search]) if params[:search].present?\n    @users = @users.page(params[:page]).per(params[:per_page] || 25)\n\n    render json: {\n      data: ActiveModelSerializers::SerializableResource.new(@users),\n      meta: pagination_meta(@users)\n    }\n  end\n\n  # GET /api/v1/users/:id\n  def show\n    render json: @user, serializer: UserSerializer\n  end\n\n  # POST /api/v1/users\n  def create\n    @user = User.new(user_params)\n\n    if @user.save\n      render json: @user, serializer: UserSerializer, status: :created\n    else\n      render json: { \n        error: 'User creation failed', \n        details: @user.errors.full_messages \n      }, status: :unprocessable_entity\n    end\n  end\n\n  # PATCH/PUT /api/v1/users/:id\n  def update\n    if @user.update(user_params)\n      render json: @user, serializer: UserSerializer\n    else\n      render json: { \n        error: 'User update failed', \n        details: @user.errors.full_messages \n      }, status: :unprocessable_entity\n    end\n  end\n\n  # DELETE /api/v1/users/:id\n  def destroy\n    @user.destroy\n    head :no_content\n  end\n\n  private\n\n  def set_user\n    @user = User.find(params[:id])\n  end\n\n  def user_params\n    params.require(:user).permit(:name, :email, :password, :is_active)\n  end\n\n  def pagination_meta(collection)\n    {\n      current_page: collection.current_page,\n      per_page: collection.limit_value,\n      total_pages: collection.total_pages,\n      total_count: collection.total_count\n    }\n  end\nend\n```\n\n### Serializers\n```ruby\n# app/serializers/user_serializer.rb\nclass UserSerializer < ActiveModel::Serializer\n  attributes :id, :name, :email, :is_active, :created_at, :updated_at\n\n  has_many :posts, serializer: PostSerializer\n\n  def created_at\n    object.created_at.iso8601\n  end\n\n  def updated_at\n    object.updated_at.iso8601\n  end\nend\n\n# app/serializers/post_serializer.rb\nclass PostSerializer < ActiveModel::Serializer\n  attributes :id, :title, :content, :status, :created_at, :updated_at\n\n  belongs_to :user, serializer: UserSerializer\n  has_many :comments, serializer: CommentSerializer\n\n  def created_at\n    object.created_at.iso8601\n  end\n\n  def updated_at\n    object.updated_at.iso8601\n  end\nend\n```\n\n### Service Objects\n```ruby\n# app/services/user_service.rb\nclass UserService\n  def self.create(params)\n    user = User.new(params)\n    \n    if user.save\n      # Send welcome email in background\n      UserMailer.welcome_email(user).deliver_later\n      \n      # Create user profile\n      UserProfile.create(user: user)\n      \n      user\n    else\n      raise ActiveRecord::RecordInvalid, user\n    end\n  end\n\n  def self.authenticate(email, password)\n    user = User.find_by(email: email.downcase)\n    \n    if user&.authenticate(password) && user.active?\n      user\n    else\n      nil\n    end\n  end\n\n  def self.generate_jwt_token(user)\n    payload = {\n      user_id: user.id,\n      email: user.email,\n      exp: 24.hours.from_now.to_i\n    }\n    \n    JWT.encode(payload, Rails.application.secret_key_base, 'HS256')\n  end\nend\n```\n\n### Database Migrations\n```ruby\n# db/migrate/20241201000001_create_users.rb\nclass CreateUsers < ActiveRecord::Migration[7.1]\n  def change\n    create_table :users do |t|\n      t.string :name, null: false\n      t.string :email, null: false\n      t.string :password_digest, null: false\n      t.boolean :is_active, default: true\n      t.timestamps\n    end\n\n    add_index :users, :email, unique: true\n    add_index :users, :is_active\n  end\nend\n\n# db/migrate/20241201000002_create_posts.rb\nclass CreatePosts < ActiveRecord::Migration[7.1]\n  def change\n    create_table :posts do |t|\n      t.string :title, null: false\n      t.text :content, null: false\n      t.integer :status, default: 0\n      t.references :user, null: false, foreign_key: true\n      t.timestamps\n    end\n\n    add_index :posts, :status\n    add_index :posts, :created_at\n  end\nend\n```\n\n### Background Jobs\n```ruby\n# app/jobs/email_job.rb\nclass EmailJob < ApplicationJob\n  queue_as :mailers\n\n  def perform(user_id, email_type, options = {})\n    user = User.find(user_id)\n    \n    case email_type\n    when 'welcome'\n      UserMailer.welcome_email(user).deliver_now\n    when 'notification'\n      UserMailer.notification_email(user, options[:message]).deliver_now\n    end\n  end\nend\n```\n\n### Routes Configuration\n```ruby\n# config/routes.rb\nRails.application.routes.draw do\n  namespace :api do\n    namespace :v1 do\n      resources :users\n      resources :posts do\n        resources :comments, only: [:index, :create, :destroy]\n      end\n\n      # Authentication routes\n      post '/auth/login', to: 'authentication#login'\n      post '/auth/register', to: 'authentication#register'\n      delete '/auth/logout', to: 'authentication#logout'\n\n      # Health check\n      get '/health', to: 'health#check'\n    end\n  end\n\n  # Sidekiq web UI\n  require 'sidekiq/web'\n  mount Sidekiq::Web => '/sidekiq'\nend\n```\n\n### Testing with RSpec\n```ruby\n# spec/models/user_spec.rb\nrequire 'rails_helper'\n\nRSpec.describe User, type: :model do\n  describe 'validations' do\n    it 'is valid with valid attributes' do\n      user = build(:user)\n      expect(user).to be_valid\n    end\n\n    it 'is not valid without a name' do\n      user = build(:user, name: nil)\n      expect(user).not_to be_valid\n    end\n\n    it 'is not valid with duplicate email' do\n      create(:user, email: 'test@example.com')\n      user = build(:user, email: 'test@example.com')\n      expect(user).not_to be_valid\n    end\n  end\n\n  describe 'associations' do\n    it 'has many posts' do\n      association = described_class.reflect_on_association(:posts)\n      expect(association.macro).to eq :has_many\n    end\n  end\n\n  describe 'scopes' do\n    let!(:active_user) { create(:user, is_active: true) }\n    let!(:inactive_user) { create(:user, is_active: false) }\n\n    it 'returns only active users' do\n      expect(User.active).to include(active_user)\n      expect(User.active).not_to include(inactive_user)\n    end\n  end\nend\n\n# spec/factories/users.rb\nFactoryBot.define do\n  factory :user do\n    name { Faker::Name.name }\n    email { Faker::Internet.email }\n    password { 'password123' }\n    is_active { true }\n  end\nend\n```\n\n## Testing\n\n- Use RSpec for testing framework\n- Use FactoryBot for test data\n- Test models, controllers, and services\n- Use VCR for external API testing\n- Write integration tests for API endpoints\n\n## Database\n\n- Use ActiveRecord for ORM operations\n- Write proper database migrations\n- Use database indexing for performance\n- Implement database seeds for development\n- Use database transactions for complex operations\n\n## Deployment\n\n- Use Capistrano for deployment\n- Configure for production environment\n- Set up background job processing\n- Implement proper logging\n- Use environment-specific configurations",
      "tags": [
        {
          "tag": {
            "id": "ruby",
            "name": "ruby",
            "slug": "ruby"
          }
        },
        {
          "tag": {
            "id": "rails",
            "name": "rails",
            "slug": "rails"
          }
        },
        {
          "tag": {
            "id": "activerecord",
            "name": "activerecord",
            "slug": "activerecord"
          }
        },
        {
          "tag": {
            "id": "api",
            "name": "api",
            "slug": "api"
          }
        },
        {
          "tag": {
            "id": "ruby-on-rails",
            "name": "ruby-on-rails",
            "slug": "ruby-on-rails"
          }
        }
      ],
      "author": {
        "name": "Claude Code Community",
        "url": "https://github.com/claudecode-community"
      },
      "stats": {
        "votes": 43,
        "copies": 167
      },
      "_count": {
        "votes": 56,
        "copies": 188
      },
      "difficulty": "INTERMEDIATE",
      "language": "Ruby",
      "framework": "Ruby on Rails",
      "lastUpdated": "2024-12-01",
      "featured": false
    },
    {
      "id": "jupyter-ml-project",
      "title": "Jupyter ML Project + Python",
      "slug": "jupyter-ml-project-python",
      "tagline": "Jupyter configuration for intermediate developers",
      "description": "Complete machine learning project setup with Jupyter notebooks, data analysis, and model development workflows.",
      "categoryId": "claude-configs",
      "category": {
        "id": "claude-configs",
        "name": "Claude.md Configurations",
        "slug": "claude-configs",
        "description": "Ready-to-use Claude.md configuration files for different tech stacks and project types.",
        "icon": "ðŸ“‹",
        "color": "#F59E0B"
      },
      "type": "CONFIGURATION",
      "content": "# Claude.md - Jupyter ML Project + Python\n\n## Project Overview\n\nThis is a comprehensive machine learning project setup using Jupyter notebooks, pandas for data manipulation, scikit-learn for modeling, and modern Python data science practices.\n\n## Technology Stack\n\n- **Language**: Python 3.9+\n- **Environment**: Jupyter Lab/Notebook\n- **Data Processing**: Pandas, NumPy\n- **Visualization**: Matplotlib, Seaborn, Plotly\n- **ML Library**: Scikit-learn, XGBoost\n- **Model Deployment**: MLflow, FastAPI\n- **Version Control**: DVC (Data Version Control)\n\n## Project Structure\n\n```\nâ”œâ”€â”€ data/\nâ”‚   â”œâ”€â”€ raw/             # Original, immutable data\nâ”‚   â”œâ”€â”€ interim/         # Intermediate data (cleaned)\nâ”‚   â”œâ”€â”€ processed/       # Final datasets for modeling\nâ”‚   â””â”€â”€ external/        # External data sources\nâ”œâ”€â”€ notebooks/\nâ”‚   â”œâ”€â”€ exploratory/     # EDA notebooks\nâ”‚   â”œâ”€â”€ modeling/        # Model development\nâ”‚   â””â”€â”€ reporting/       # Final analysis\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ data/           # Data processing scripts\nâ”‚   â”œâ”€â”€ features/       # Feature engineering\nâ”‚   â”œâ”€â”€ models/         # Model training/prediction\nâ”‚   â””â”€â”€ visualization/ # Plotting utilities\nâ”œâ”€â”€ models/             # Trained model artifacts\nâ”œâ”€â”€ reports/            # Analysis reports\nâ””â”€â”€ requirements.txt    # Python dependencies\n```\n\n## Development Guidelines\n\n### Code Style\n- Follow PEP 8 style guidelines\n- Use type hints for functions\n- Document functions with docstrings\n- Keep notebooks clean and well-documented\n- Use meaningful variable names\n\n### Data Science Workflow\n- Start with exploratory data analysis (EDA)\n- Follow the CRISP-DM methodology\n- Version control data with DVC\n- Validate data quality at each step\n- Document assumptions and decisions\n\n### Reproducibility\n- Set random seeds for reproducible results\n- Use environment.yml for dependencies\n- Document data sources and preprocessing steps\n- Create automated pipelines where possible\n- Track experiments with MLflow\n\n## Key Commands\n\n- `jupyter lab` - Start Jupyter Lab\n- `jupyter notebook` - Start Jupyter Notebook\n- `python -m pip install -r requirements.txt` - Install dependencies\n- `python src/data/make_dataset.py` - Process raw data\n- `python src/models/train_model.py` - Train model\n- `mlflow ui` - View experiment tracking\n\n## Environment Setup\n\nCreate a `requirements.txt` file:\n```\n# Core data science stack\npandas==2.1.4\nnumpy==1.24.3\nmatplotlib==3.7.2\nseaborn==0.12.2\nplotly==5.17.0\n\n# Machine learning\nscikit-learn==1.3.2\nxgboost==2.0.2\nlightgbm==4.1.0\n\n# Jupyter environment\njupyter==1.0.0\njupyterlab==4.0.9\nipykernel==6.27.1\nipywidgets==8.1.1\n\n# Model tracking and deployment\nmlflow==2.8.1\nfastapi==0.104.1\nuvicorn==0.24.0\n\n# Data version control\ndvc==3.30.1\n\n# Utilities\npython-dotenv==1.0.0\nrequests==2.31.0\ntqdm==4.66.1\n```\n\n## Common Patterns\n\n### Data Loading and Exploration\n```python\n# notebooks/exploratory/01_data_exploration.ipynb\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set up plotting\nplt.style.use('seaborn-v0_8')\nsns.set_palette(\"husl\")\n\n# Load data\ndef load_data(filepath: str) -> pd.DataFrame:\n    \"\"\"Load dataset from CSV file.\"\"\"\n    data_path = Path(filepath)\n    if not data_path.exists():\n        raise FileNotFoundError(f\"Data file not found: {filepath}\")\n    \n    df = pd.read_csv(data_path)\n    print(f\"Data loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n    return df\n\n# Basic data exploration\ndef explore_data(df: pd.DataFrame) -> None:\n    \"\"\"Perform basic data exploration.\"\"\"\n    print(\"=== Dataset Overview ===\")\n    print(f\"Shape: {df.shape}\")\n    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n    \n    print(\"\\n=== Data Types ===\")\n    print(df.dtypes.value_counts())\n    \n    print(\"\\n=== Missing Values ===\")\n    missing = df.isnull().sum()\n    missing_pct = (missing / len(df)) * 100\n    missing_df = pd.DataFrame({\n        'Missing Count': missing,\n        'Missing %': missing_pct\n    })\n    print(missing_df[missing_df['Missing Count'] > 0])\n    \n    print(\"\\n=== Numerical Summary ===\")\n    print(df.describe())\n\n# Load and explore data\ndf = load_data('../data/raw/dataset.csv')\nexplore_data(df)\n\n# Visualize distributions\ndef plot_distributions(df: pd.DataFrame, columns: list, figsize: tuple = (15, 10)):\n    \"\"\"Plot distributions for numerical columns.\"\"\"\n    n_cols = len(columns)\n    n_rows = (n_cols + 2) // 3\n    \n    fig, axes = plt.subplots(n_rows, 3, figsize=figsize)\n    axes = axes.flatten() if n_rows > 1 else [axes]\n    \n    for i, col in enumerate(columns):\n        if i < len(axes):\n            df[col].hist(bins=30, ax=axes[i], alpha=0.7)\n            axes[i].set_title(f'Distribution of {col}')\n            axes[i].set_xlabel(col)\n            axes[i].set_ylabel('Frequency')\n    \n    # Hide empty subplots\n    for i in range(len(columns), len(axes)):\n        axes[i].hide()\n    \n    plt.tight_layout()\n    plt.show()\n\n# Plot numerical distributions\nnumerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\nplot_distributions(df, numerical_cols[:9])  # Plot first 9 numerical columns\n```\n\n### Feature Engineering\n```python\n# src/features/build_features.py\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import (\n    StandardScaler, \n    MinMaxScaler, \n    LabelEncoder, \n    OneHotEncoder\n)\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom typing import List, Tuple, Dict, Any\n\nclass FeatureEngineer:\n    \"\"\"Feature engineering pipeline for ML projects.\"\"\"\n    \n    def __init__(self):\n        self.scalers = {}\n        self.encoders = {}\n        self.feature_selectors = {}\n    \n    def create_datetime_features(self, df: pd.DataFrame, date_col: str) -> pd.DataFrame:\n        \"\"\"Extract datetime features from date column.\"\"\"\n        df = df.copy()\n        df[date_col] = pd.to_datetime(df[date_col])\n        \n        # Extract datetime components\n        df[f'{date_col}_year'] = df[date_col].dt.year\n        df[f'{date_col}_month'] = df[date_col].dt.month\n        df[f'{date_col}_day'] = df[date_col].dt.day\n        df[f'{date_col}_dayofweek'] = df[date_col].dt.dayofweek\n        df[f'{date_col}_quarter'] = df[date_col].dt.quarter\n        df[f'{date_col}_is_weekend'] = df[date_col].dt.dayofweek.isin([5, 6]).astype(int)\n        \n        return df\n    \n    def create_interaction_features(self, df: pd.DataFrame, col_pairs: List[Tuple[str, str]]) -> pd.DataFrame:\n        \"\"\"Create interaction features between column pairs.\"\"\"\n        df = df.copy()\n        \n        for col1, col2 in col_pairs:\n            if col1 in df.columns and col2 in df.columns:\n                # Multiplication interaction\n                df[f'{col1}_{col2}_mult'] = df[col1] * df[col2]\n                \n                # Division interaction (avoid division by zero)\n                df[f'{col1}_{col2}_div'] = df[col1] / (df[col2] + 1e-8)\n                \n                # Difference\n                df[f'{col1}_{col2}_diff'] = df[col1] - df[col2]\n        \n        return df\n    \n    def encode_categorical_features(self, df: pd.DataFrame, categorical_cols: List[str], \n                                  method: str = 'onehot') -> pd.DataFrame:\n        \"\"\"Encode categorical features.\"\"\"\n        df = df.copy()\n        \n        for col in categorical_cols:\n            if col not in df.columns:\n                continue\n                \n            if method == 'onehot':\n                encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n                encoded = encoder.fit_transform(df[[col]])\n                \n                # Create column names\n                feature_names = [f'{col}_{val}' for val in encoder.categories_[0]]\n                encoded_df = pd.DataFrame(encoded, columns=feature_names, index=df.index)\n                \n                # Store encoder and merge\n                self.encoders[col] = encoder\n                df = pd.concat([df.drop(col, axis=1), encoded_df], axis=1)\n                \n            elif method == 'label':\n                encoder = LabelEncoder()\n                df[col] = encoder.fit_transform(df[col].astype(str))\n                self.encoders[col] = encoder\n        \n        return df\n    \n    def scale_numerical_features(self, df: pd.DataFrame, numerical_cols: List[str], \n                                method: str = 'standard') -> pd.DataFrame:\n        \"\"\"Scale numerical features.\"\"\"\n        df = df.copy()\n        \n        if method == 'standard':\n            scaler = StandardScaler()\n        elif method == 'minmax':\n            scaler = MinMaxScaler()\n        else:\n            raise ValueError(\"Method must be 'standard' or 'minmax'\")\n        \n        df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n        self.scalers['numerical'] = scaler\n        \n        return df\n    \n    def select_features(self, X: pd.DataFrame, y: pd.Series, k: int = 10) -> pd.DataFrame:\n        \"\"\"Select top k features using univariate selection.\"\"\"\n        selector = SelectKBest(score_func=f_classif, k=k)\n        X_selected = selector.fit_transform(X, y)\n        \n        # Get selected feature names\n        selected_features = X.columns[selector.get_support()].tolist()\n        self.feature_selectors['univariate'] = selector\n        \n        return pd.DataFrame(X_selected, columns=selected_features, index=X.index)\n\n# Usage example\ndef create_features(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Complete feature engineering pipeline.\"\"\"\n    engineer = FeatureEngineer()\n    \n    # Create datetime features if date column exists\n    if 'date' in df.columns:\n        df = engineer.create_datetime_features(df, 'date')\n    \n    # Create interaction features\n    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n    if len(numerical_cols) >= 2:\n        interactions = [(numerical_cols[i], numerical_cols[i+1]) \n                       for i in range(min(3, len(numerical_cols)-1))]\n        df = engineer.create_interaction_features(df, interactions)\n    \n    # Encode categorical features\n    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n    if categorical_cols:\n        df = engineer.encode_categorical_features(df, categorical_cols, method='onehot')\n    \n    return df, engineer\n```\n\n### Model Training and Evaluation\n```python\n# src/models/train_model.py\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\nimport xgboost as xgb\nimport mlflow\nimport mlflow.sklearn\nfrom typing import Dict, Any, Tuple\nimport joblib\nfrom pathlib import Path\n\nclass ModelTrainer:\n    \"\"\"ML model training and evaluation pipeline.\"\"\"\n    \n    def __init__(self, experiment_name: str = \"ml_experiment\"):\n        self.models = {}\n        self.best_model = None\n        self.experiment_name = experiment_name\n        mlflow.set_experiment(experiment_name)\n    \n    def prepare_models(self) -> Dict[str, Any]:\n        \"\"\"Initialize different models for comparison.\"\"\"\n        models = {\n            'logistic_regression': LogisticRegression(random_state=42),\n            'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),\n            'gradient_boosting': GradientBoostingClassifier(random_state=42),\n            'xgboost': xgb.XGBClassifier(random_state=42)\n        }\n        return models\n    \n    def train_evaluate_model(self, model, X_train: pd.DataFrame, X_test: pd.DataFrame,\n                           y_train: pd.Series, y_test: pd.Series, model_name: str) -> Dict[str, float]:\n        \"\"\"Train and evaluate a single model.\"\"\"\n        with mlflow.start_run(run_name=model_name):\n            # Train model\n            model.fit(X_train, y_train)\n            \n            # Predictions\n            y_pred = model.predict(X_test)\n            y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n            \n            # Calculate metrics\n            accuracy = model.score(X_test, y_test)\n            auc_score = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else 0\n            \n            # Cross-validation\n            cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n            cv_mean = cv_scores.mean()\n            cv_std = cv_scores.std()\n            \n            # Log metrics\n            mlflow.log_metric(\"accuracy\", accuracy)\n            mlflow.log_metric(\"auc_score\", auc_score)\n            mlflow.log_metric(\"cv_mean\", cv_mean)\n            mlflow.log_metric(\"cv_std\", cv_std)\n            \n            # Log model\n            mlflow.sklearn.log_model(model, model_name)\n            \n            # Print results\n            print(f\"\\n{model_name.upper()} Results:\")\n            print(f\"Accuracy: {accuracy:.4f}\")\n            print(f\"AUC Score: {auc_score:.4f}\")\n            print(f\"CV Mean: {cv_mean:.4f} (+/- {cv_std * 2:.4f})\")\n            print(\"\\nClassification Report:\")\n            print(classification_report(y_test, y_pred))\n            \n            return {\n                'model': model,\n                'accuracy': accuracy,\n                'auc_score': auc_score,\n                'cv_mean': cv_mean,\n                'cv_std': cv_std\n            }\n    \n    def hyperparameter_tuning(self, model, param_grid: Dict[str, list], \n                            X_train: pd.DataFrame, y_train: pd.Series) -> Any:\n        \"\"\"Perform hyperparameter tuning using GridSearchCV.\"\"\"\n        grid_search = GridSearchCV(\n            model, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1\n        )\n        grid_search.fit(X_train, y_train)\n        \n        print(f\"Best parameters: {grid_search.best_params_}\")\n        print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n        \n        return grid_search.best_estimator_\n    \n    def train_all_models(self, X_train: pd.DataFrame, X_test: pd.DataFrame,\n                        y_train: pd.Series, y_test: pd.Series) -> Dict[str, Dict[str, Any]]:\n        \"\"\"Train and compare multiple models.\"\"\"\n        models = self.prepare_models()\n        results = {}\n        \n        for name, model in models.items():\n            print(f\"\\nTraining {name}...\")\n            result = self.train_evaluate_model(model, X_train, X_test, y_train, y_test, name)\n            results[name] = result\n        \n        # Find best model\n        best_model_name = max(results.keys(), key=lambda x: results[x]['accuracy'])\n        self.best_model = results[best_model_name]['model']\n        \n        print(f\"\\nBest model: {best_model_name} with accuracy: {results[best_model_name]['accuracy']:.4f}\")\n        \n        return results\n    \n    def save_model(self, model, filepath: str) -> None:\n        \"\"\"Save trained model to disk.\"\"\"\n        Path(filepath).parent.mkdir(parents=True, exist_ok=True)\n        joblib.dump(model, filepath)\n        print(f\"Model saved to {filepath}\")\n\n# Usage example\ndef main():\n    \"\"\"Main training pipeline.\"\"\"\n    # Load processed data\n    df = pd.read_csv('../data/processed/features.csv')\n    \n    # Separate features and target\n    X = df.drop('target', axis=1)\n    y = df['target']\n    \n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42, stratify=y\n    )\n    \n    print(f\"Training set size: {X_train.shape}\")\n    print(f\"Test set size: {X_test.shape}\")\n    \n    # Train models\n    trainer = ModelTrainer(\"house_price_prediction\")\n    results = trainer.train_all_models(X_train, X_test, y_train, y_test)\n    \n    # Save best model\n    trainer.save_model(trainer.best_model, '../models/best_model.joblib')\n    \n    return results\n\nif __name__ == \"__main__\":\n    results = main()\n```\n\n### Model Deployment\n```python\n# src/models/predict_model.py\nimport joblib\nimport pandas as pd\nimport numpy as np\nfrom fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\nfrom typing import List\nimport logging\n\n# Set up logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Load trained model\nmodel = joblib.load('../models/best_model.joblib')\n\n# FastAPI app\napp = FastAPI(title=\"ML Model API\", version=\"1.0.0\")\n\nclass PredictionInput(BaseModel):\n    features: List[float]\n\nclass PredictionOutput(BaseModel):\n    prediction: float\n    probability: List[float]\n\n@app.post(\"/predict\", response_model=PredictionOutput)\nasync def predict(input_data: PredictionInput):\n    \"\"\"Make prediction using trained model.\"\"\"\n    try:\n        # Convert input to numpy array\n        features = np.array(input_data.features).reshape(1, -1)\n        \n        # Make prediction\n        prediction = model.predict(features)[0]\n        probability = model.predict_proba(features)[0].tolist()\n        \n        logger.info(f\"Prediction made: {prediction}\")\n        \n        return PredictionOutput(\n            prediction=float(prediction),\n            probability=probability\n        )\n    \n    except Exception as e:\n        logger.error(f\"Prediction error: {str(e)}\")\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.get(\"/health\")\nasync def health_check():\n    \"\"\"Health check endpoint.\"\"\"\n    return {\"status\": \"healthy\"}\n\n# Run with: uvicorn predict_model:app --reload\n```\n\n## Data Version Control\n\n- Use DVC for data versioning\n- Track large datasets and model artifacts\n- Create reproducible data pipelines\n- Share data across team members\n- Maintain data lineage\n\n## Model Tracking\n\n- Use MLflow for experiment tracking\n- Log hyperparameters and metrics\n- Compare model performance\n- Store model artifacts\n- Enable model deployment\n\n## Best Practices\n\n- Always validate data quality\n- Use cross-validation for model evaluation\n- Document data sources and transformations\n- Create automated testing for data pipelines\n- Monitor model performance in production",
      "tags": [
        {
          "tag": {
            "id": "python",
            "name": "python",
            "slug": "python"
          }
        },
        {
          "tag": {
            "id": "jupyter",
            "name": "jupyter",
            "slug": "jupyter"
          }
        },
        {
          "tag": {
            "id": "machine-learning",
            "name": "machine-learning",
            "slug": "machine-learning"
          }
        },
        {
          "tag": {
            "id": "pandas",
            "name": "pandas",
            "slug": "pandas"
          }
        },
        {
          "tag": {
            "id": "scikit-learn",
            "name": "scikit-learn",
            "slug": "scikit-learn"
          }
        }
      ],
      "author": {
        "name": "Claude Code Community",
        "url": "https://github.com/claudecode-community"
      },
      "stats": {
        "votes": 49,
        "copies": 223
      },
      "_count": {
        "votes": 14,
        "copies": 203
      },
      "difficulty": "INTERMEDIATE",
      "language": "Python",
      "framework": "Jupyter",
      "lastUpdated": "2024-12-01",
      "featured": true
    },
    {
      "id": "pytorch-deep-learning",
      "title": "PyTorch Deep Learning + GPU",
      "slug": "pytorch-deep-learning-gpu",
      "tagline": "PyTorch configuration for advanced developers",
      "description": "Deep learning project setup with PyTorch, GPU acceleration, and modern ML practices for neural network development.",
      "categoryId": "claude-configs",
      "category": {
        "id": "claude-configs",
        "name": "Claude.md Configurations",
        "slug": "claude-configs",
        "description": "Ready-to-use Claude.md configuration files for different tech stacks and project types.",
        "icon": "ðŸ“‹",
        "color": "#F59E0B"
      },
      "type": "CONFIGURATION",
      "content": "# Claude.md - PyTorch Deep Learning + GPU\n\n## Project Overview\n\nThis is a comprehensive deep learning project setup using PyTorch with GPU acceleration, modern neural network architectures, and MLOps practices for scalable deep learning development.\n\n## Technology Stack\n\n- **Deep Learning**: PyTorch 2.0+\n- **Language**: Python 3.9+\n- **GPU**: CUDA 11.8+ / ROCm (AMD)\n- **Data Processing**: torchvision, albumentations\n- **Visualization**: TensorBoard, wandb\n- **Model Serving**: TorchServe, ONNX\n- **Containers**: Docker with CUDA support\n\n## Project Structure\n\n```\nâ”œâ”€â”€ data/\nâ”‚   â”œâ”€â”€ raw/             # Original datasets\nâ”‚   â”œâ”€â”€ processed/       # Preprocessed datasets\nâ”‚   â””â”€â”€ splits/          # Train/val/test splits\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ data/           # Data loading and preprocessing\nâ”‚   â”œâ”€â”€ models/         # Model architectures\nâ”‚   â”œâ”€â”€ training/       # Training loops and utilities\nâ”‚   â”œâ”€â”€ evaluation/     # Evaluation and metrics\nâ”‚   â””â”€â”€ utils/          # Utility functions\nâ”œâ”€â”€ configs/            # Configuration files\nâ”œâ”€â”€ notebooks/          # Jupyter notebooks\nâ”œâ”€â”€ experiments/        # Experiment logs and outputs\nâ”œâ”€â”€ checkpoints/        # Model checkpoints\nâ””â”€â”€ docker/            # Docker configurations\n```\n\n## Development Guidelines\n\n### Code Style\n- Follow PyTorch Lightning patterns\n- Use type hints and docstrings\n- Implement proper error handling\n- Use configuration files for hyperparameters\n- Follow modular design principles\n\n### Deep Learning Best Practices\n- Use proper data augmentation\n- Implement learning rate scheduling\n- Use gradient clipping when needed\n- Monitor training with visualizations\n- Implement early stopping\n\n### GPU Optimization\n- Use mixed precision training\n- Optimize data loading with multiple workers\n- Use compiled models when possible\n- Monitor GPU utilization\n- Implement distributed training for large models\n\n## Key Commands\n\n- `python train.py --config configs/config.yaml` - Start training\n- `python evaluate.py --checkpoint path/to/model.pth` - Evaluate model\n- `tensorboard --logdir experiments/` - View training logs\n- `python -m torch.distributed.launch --nproc_per_node=2 train.py` - Multi-GPU training\n\n## Environment Setup\n\nCreate a `requirements.txt` file:\n```\n# Core PyTorch stack\ntorch==2.1.1\ntorchvision==0.16.1\ntorchaudio==2.1.1\npytorch-lightning==2.1.2\n\n# Data processing\nalbumentations==1.3.1\nopencv-python==4.8.1.78\npillow==10.1.0\nnumpy==1.24.3\npandas==2.1.4\n\n# Visualization and logging\ntensorboard==2.15.1\nwandb==0.16.0\nmatplotlib==3.7.2\nseaborn==0.12.2\n\n# Model optimization\ntorchmetrics==1.2.0\ntimm==0.9.12\ntransformers==4.36.0\n\n# Deployment\nonnx==1.15.0\nonnxruntime-gpu==1.16.3\ntorchserve==0.8.2\n\n# Development\njupyter==1.0.0\nblack==23.11.0\npytest==7.4.3\n```\n\n## Common Patterns\n\n### Data Loading and Preprocessing\n```python\n# src/data/dataset.py\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport cv2\nimport pandas as pd\nfrom pathlib import Path\nfrom typing import Tuple, Optional, Callable\n\nclass CustomDataset(Dataset):\n    \"\"\"Custom dataset class for image classification.\"\"\"\n    \n    def __init__(self, \n                 data_dir: str,\n                 csv_file: str,\n                 transform: Optional[Callable] = None,\n                 mode: str = 'train'):\n        self.data_dir = Path(data_dir)\n        self.df = pd.read_csv(csv_file)\n        self.transform = transform\n        self.mode = mode\n        \n    def __len__(self) -> int:\n        return len(self.df)\n    \n    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n        row = self.df.iloc[idx]\n        \n        # Load image\n        img_path = self.data_dir / row['image_path']\n        image = cv2.imread(str(img_path))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        # Load label\n        label = torch.tensor(row['label'], dtype=torch.long)\n        \n        # Apply transforms\n        if self.transform:\n            if isinstance(self.transform, A.Compose):\n                transformed = self.transform(image=image)\n                image = transformed['image']\n            else:\n                image = self.transform(image)\n        \n        return image, label\n\ndef get_transforms(image_size: int = 224, mode: str = 'train') -> A.Compose:\n    \"\"\"Get image transforms for training or validation.\"\"\"\n    if mode == 'train':\n        transform = A.Compose([\n            A.Resize(image_size, image_size),\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.2),\n            A.Rotate(limit=30, p=0.5),\n            A.RandomBrightnessContrast(p=0.5),\n            A.HueSaturationValue(p=0.3),\n            A.GaussNoise(p=0.2),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225]\n            ),\n            ToTensorV2()\n        ])\n    else:\n        transform = A.Compose([\n            A.Resize(image_size, image_size),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225]\n            ),\n            ToTensorV2()\n        ])\n    \n    return transform\n\ndef create_data_loaders(train_dataset: Dataset, \n                       val_dataset: Dataset,\n                       batch_size: int = 32,\n                       num_workers: int = 4) -> Tuple[DataLoader, DataLoader]:\n    \"\"\"Create training and validation data loaders.\"\"\"\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=num_workers,\n        pin_memory=True,\n        persistent_workers=True\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        pin_memory=True,\n        persistent_workers=True\n    )\n    \n    return train_loader, val_loader\n```\n\n### Model Architecture\n```python\n# src/models/cnn_model.py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport timm\nfrom typing import Optional\n\nclass CNNModel(nn.Module):\n    \"\"\"Custom CNN model with pretrained backbone.\"\"\"\n    \n    def __init__(self, \n                 model_name: str = 'resnet50',\n                 num_classes: int = 10,\n                 pretrained: bool = True,\n                 dropout: float = 0.2):\n        super(CNNModel, self).__init__()\n        \n        # Load pretrained backbone\n        self.backbone = timm.create_model(\n            model_name,\n            pretrained=pretrained,\n            num_classes=0,  # Remove classification head\n            global_pool=''  # Remove global pooling\n        )\n        \n        # Get feature size\n        with torch.no_grad():\n            dummy_input = torch.randn(1, 3, 224, 224)\n            features = self.backbone(dummy_input)\n            feature_size = features.view(features.size(0), -1).size(1)\n        \n        # Custom classification head\n        self.classifier = nn.Sequential(\n            nn.AdaptiveAvgPool2d((1, 1)),\n            nn.Flatten(),\n            nn.Dropout(dropout),\n            nn.Linear(feature_size, 512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(dropout),\n            nn.Linear(512, num_classes)\n        )\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        features = self.backbone(x)\n        output = self.classifier(features)\n        return output\n\nclass AttentionBlock(nn.Module):\n    \"\"\"Self-attention block for improved feature representation.\"\"\"\n    \n    def __init__(self, in_channels: int):\n        super(AttentionBlock, self).__init__()\n        self.query_conv = nn.Conv2d(in_channels, in_channels // 8, 1)\n        self.key_conv = nn.Conv2d(in_channels, in_channels // 8, 1)\n        self.value_conv = nn.Conv2d(in_channels, in_channels, 1)\n        self.softmax = nn.Softmax(dim=-2)\n        self.gamma = nn.Parameter(torch.zeros(1))\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        batch_size, channels, height, width = x.size()\n        \n        # Generate query, key, value\n        query = self.query_conv(x).view(batch_size, -1, height * width)\n        key = self.key_conv(x).view(batch_size, -1, height * width)\n        value = self.value_conv(x).view(batch_size, -1, height * width)\n        \n        # Compute attention\n        attention = torch.bmm(query.permute(0, 2, 1), key)\n        attention = self.softmax(attention)\n        \n        # Apply attention to values\n        out = torch.bmm(value, attention.permute(0, 2, 1))\n        out = out.view(batch_size, channels, height, width)\n        \n        # Add residual connection\n        out = self.gamma * out + x\n        return out\n\nclass ResidualBlock(nn.Module):\n    \"\"\"Residual block with batch normalization.\"\"\"\n    \n    def __init__(self, in_channels: int, out_channels: int, stride: int = 1):\n        super(ResidualBlock, self).__init__()\n        \n        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, 1, stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        residual = self.shortcut(x)\n        \n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += residual\n        out = F.relu(out)\n        \n        return out\n```\n\n### Training Loop\n```python\n# src/training/trainer.py\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torch.utils.tensorboard import SummaryWriter\nimport numpy as np\nfrom tqdm import tqdm\nfrom typing import Dict, List, Optional, Tuple\nimport wandb\nfrom pathlib import Path\n\nclass Trainer:\n    \"\"\"Training class with modern PyTorch features.\"\"\"\n    \n    def __init__(self,\n                 model: nn.Module,\n                 train_loader: DataLoader,\n                 val_loader: DataLoader,\n                 criterion: nn.Module,\n                 optimizer: optim.Optimizer,\n                 scheduler: Optional[optim.lr_scheduler._LRScheduler] = None,\n                 device: str = 'cuda',\n                 mixed_precision: bool = True,\n                 gradient_clip: float = 1.0,\n                 experiment_name: str = 'experiment'):\n        \n        self.model = model.to(device)\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.criterion = criterion\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.device = device\n        self.mixed_precision = mixed_precision\n        self.gradient_clip = gradient_clip\n        \n        # Initialize scaler for mixed precision\n        self.scaler = GradScaler() if mixed_precision else None\n        \n        # Initialize logging\n        self.writer = SummaryWriter(f'experiments/{experiment_name}')\n        self.best_val_acc = 0.0\n        self.train_losses = []\n        self.val_losses = []\n        self.val_accuracies = []\n        \n        # Compile model for better performance (PyTorch 2.0+)\n        if hasattr(torch, 'compile'):\n            self.model = torch.compile(self.model)\n    \n    def train_epoch(self) -> float:\n        \"\"\"Train for one epoch.\"\"\"\n        self.model.train()\n        running_loss = 0.0\n        num_batches = len(self.train_loader)\n        \n        progress_bar = tqdm(self.train_loader, desc='Training')\n        \n        for batch_idx, (data, targets) in enumerate(progress_bar):\n            data, targets = data.to(self.device), targets.to(self.device)\n            \n            self.optimizer.zero_grad()\n            \n            if self.mixed_precision:\n                with autocast():\n                    outputs = self.model(data)\n                    loss = self.criterion(outputs, targets)\n                \n                self.scaler.scale(loss).backward()\n                \n                # Gradient clipping\n                if self.gradient_clip > 0:\n                    self.scaler.unscale_(self.optimizer)\n                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip)\n                \n                self.scaler.step(self.optimizer)\n                self.scaler.update()\n            else:\n                outputs = self.model(data)\n                loss = self.criterion(outputs, targets)\n                loss.backward()\n                \n                # Gradient clipping\n                if self.gradient_clip > 0:\n                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip)\n                \n                self.optimizer.step()\n            \n            running_loss += loss.item()\n            \n            # Update progress bar\n            progress_bar.set_postfix({\n                'Loss': f'{loss.item():.4f}',\n                'LR': f'{self.optimizer.param_groups[0][\"lr\"]:.6f}'\n            })\n        \n        return running_loss / num_batches\n    \n    def validate_epoch(self) -> Tuple[float, float]:\n        \"\"\"Validate for one epoch.\"\"\"\n        self.model.eval()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        \n        with torch.no_grad():\n            for data, targets in tqdm(self.val_loader, desc='Validation'):\n                data, targets = data.to(self.device), targets.to(self.device)\n                \n                if self.mixed_precision:\n                    with autocast():\n                        outputs = self.model(data)\n                        loss = self.criterion(outputs, targets)\n                else:\n                    outputs = self.model(data)\n                    loss = self.criterion(outputs, targets)\n                \n                running_loss += loss.item()\n                \n                # Calculate accuracy\n                _, predicted = torch.max(outputs, 1)\n                total += targets.size(0)\n                correct += (predicted == targets).sum().item()\n        \n        val_loss = running_loss / len(self.val_loader)\n        val_acc = 100 * correct / total\n        \n        return val_loss, val_acc\n    \n    def train(self, epochs: int, save_dir: str = 'checkpoints') -> Dict[str, List[float]]:\n        \"\"\"Complete training loop.\"\"\"\n        Path(save_dir).mkdir(exist_ok=True)\n        \n        for epoch in range(epochs):\n            print(f'\\nEpoch {epoch+1}/{epochs}')\n            print('-' * 50)\n            \n            # Training phase\n            train_loss = self.train_epoch()\n            \n            # Validation phase\n            val_loss, val_acc = self.validate_epoch()\n            \n            # Update learning rate\n            if self.scheduler:\n                if isinstance(self.scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n                    self.scheduler.step(val_loss)\n                else:\n                    self.scheduler.step()\n            \n            # Log metrics\n            self.writer.add_scalar('Loss/Train', train_loss, epoch)\n            self.writer.add_scalar('Loss/Validation', val_loss, epoch)\n            self.writer.add_scalar('Accuracy/Validation', val_acc, epoch)\n            self.writer.add_scalar('Learning_Rate', self.optimizer.param_groups[0]['lr'], epoch)\n            \n            # Log to wandb if available\n            if wandb.run:\n                wandb.log({\n                    'epoch': epoch,\n                    'train_loss': train_loss,\n                    'val_loss': val_loss,\n                    'val_acc': val_acc,\n                    'lr': self.optimizer.param_groups[0]['lr']\n                })\n            \n            # Save best model\n            if val_acc > self.best_val_acc:\n                self.best_val_acc = val_acc\n                torch.save({\n                    'epoch': epoch,\n                    'model_state_dict': self.model.state_dict(),\n                    'optimizer_state_dict': self.optimizer.state_dict(),\n                    'val_acc': val_acc,\n                    'val_loss': val_loss\n                }, f'{save_dir}/best_model.pth')\n                print(f'New best model saved with validation accuracy: {val_acc:.2f}%')\n            \n            # Store metrics\n            self.train_losses.append(train_loss)\n            self.val_losses.append(val_loss)\n            self.val_accuracies.append(val_acc)\n            \n            print(f'Train Loss: {train_loss:.4f}')\n            print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n        \n        self.writer.close()\n        \n        return {\n            'train_losses': self.train_losses,\n            'val_losses': self.val_losses,\n            'val_accuracies': self.val_accuracies\n        }\n\n# Usage example\ndef create_trainer(model, train_loader, val_loader, num_classes, device):\n    \"\"\"Create trainer with optimized settings.\"\"\"\n    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n    \n    optimizer = optim.AdamW(\n        model.parameters(),\n        lr=1e-3,\n        weight_decay=1e-4,\n        betas=(0.9, 0.999)\n    )\n    \n    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n        optimizer,\n        T_0=10,\n        T_mult=2,\n        eta_min=1e-6\n    )\n    \n    trainer = Trainer(\n        model=model,\n        train_loader=train_loader,\n        val_loader=val_loader,\n        criterion=criterion,\n        optimizer=optimizer,\n        scheduler=scheduler,\n        device=device,\n        mixed_precision=True,\n        gradient_clip=1.0\n    )\n    \n    return trainer\n```\n\n### Model Deployment\n```python\n# src/deployment/inference.py\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport onnx\nimport onnxruntime as ort\nimport numpy as np\nfrom PIL import Image\nfrom typing import List, Dict, Any\nimport json\n\nclass ModelInference:\n    \"\"\"Model inference class supporting PyTorch and ONNX.\"\"\"\n    \n    def __init__(self, model_path: str, model_type: str = 'pytorch'):\n        self.model_type = model_type\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        \n        if model_type == 'pytorch':\n            self.load_pytorch_model(model_path)\n        elif model_type == 'onnx':\n            self.load_onnx_model(model_path)\n        else:\n            raise ValueError(\"Model type must be 'pytorch' or 'onnx'\")\n    \n    def load_pytorch_model(self, model_path: str):\n        \"\"\"Load PyTorch model.\"\"\"\n        checkpoint = torch.load(model_path, map_location=self.device)\n        \n        # Assuming model architecture is saved or can be reconstructed\n        from src.models.cnn_model import CNNModel\n        self.model = CNNModel(num_classes=10)  # Adjust based on your model\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.model.to(self.device)\n        self.model.eval()\n    \n    def load_onnx_model(self, model_path: str):\n        \"\"\"Load ONNX model.\"\"\"\n        providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']\n        self.ort_session = ort.InferenceSession(model_path, providers=providers)\n        self.input_name = self.ort_session.get_inputs()[0].name\n        self.output_name = self.ort_session.get_outputs()[0].name\n    \n    def preprocess(self, image: Image.Image) -> torch.Tensor:\n        \"\"\"Preprocess image for inference.\"\"\"\n        transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225]\n            )\n        ])\n        \n        return transform(image).unsqueeze(0)\n    \n    def predict(self, image: Image.Image) -> Dict[str, Any]:\n        \"\"\"Make prediction on single image.\"\"\"\n        input_tensor = self.preprocess(image)\n        \n        if self.model_type == 'pytorch':\n            with torch.no_grad():\n                input_tensor = input_tensor.to(self.device)\n                outputs = self.model(input_tensor)\n                probabilities = torch.softmax(outputs, dim=1)\n                predicted_class = torch.argmax(probabilities, dim=1).item()\n                confidence = probabilities[0][predicted_class].item()\n        \n        elif self.model_type == 'onnx':\n            input_array = input_tensor.numpy()\n            outputs = self.ort_session.run([self.output_name], {self.input_name: input_array})\n            probabilities = torch.softmax(torch.tensor(outputs[0]), dim=1)\n            predicted_class = torch.argmax(probabilities, dim=1).item()\n            confidence = probabilities[0][predicted_class].item()\n        \n        return {\n            'predicted_class': predicted_class,\n            'confidence': confidence,\n            'probabilities': probabilities[0].tolist()\n        }\n    \n    def batch_predict(self, images: List[Image.Image]) -> List[Dict[str, Any]]:\n        \"\"\"Make predictions on batch of images.\"\"\"\n        results = []\n        for image in images:\n            result = self.predict(image)\n            results.append(result)\n        return results\n\ndef export_to_onnx(model: nn.Module, input_shape: tuple, output_path: str):\n    \"\"\"Export PyTorch model to ONNX format.\"\"\"\n    model.eval()\n    dummy_input = torch.randn(1, *input_shape)\n    \n    torch.onnx.export(\n        model,\n        dummy_input,\n        output_path,\n        export_params=True,\n        opset_version=11,\n        do_constant_folding=True,\n        input_names=['input'],\n        output_names=['output'],\n        dynamic_axes={\n            'input': {0: 'batch_size'},\n            'output': {0: 'batch_size'}\n        }\n    )\n    \n    print(f\"Model exported to {output_path}\")\n```\n\n## GPU Optimization\n\n- Use CUDA for GPU acceleration\n- Implement mixed precision training\n- Optimize data loading with pin_memory\n- Use multiple GPUs with DataParallel/DistributedDataParallel\n- Monitor GPU memory usage\n\n## Experiment Tracking\n\n- Use TensorBoard for training visualization\n- Integrate with Weights & Biases\n- Log hyperparameters and metrics\n- Track model checkpoints\n- Compare experiment results\n\n## Model Deployment\n\n- Export models to ONNX format\n- Use TorchServe for production serving\n- Implement proper model versioning\n- Add monitoring and logging\n- Use containerization with Docker",
      "tags": [
        {
          "tag": {
            "id": "python",
            "name": "python",
            "slug": "python"
          }
        },
        {
          "tag": {
            "id": "pytorch",
            "name": "pytorch",
            "slug": "pytorch"
          }
        },
        {
          "tag": {
            "id": "deep-learning",
            "name": "deep-learning",
            "slug": "deep-learning"
          }
        },
        {
          "tag": {
            "id": "neural-networks",
            "name": "neural-networks",
            "slug": "neural-networks"
          }
        },
        {
          "tag": {
            "id": "gpu",
            "name": "gpu",
            "slug": "gpu"
          }
        }
      ],
      "author": {
        "name": "Claude Code Community",
        "url": "https://github.com/claudecode-community"
      },
      "stats": {
        "votes": 29,
        "copies": 74
      },
      "_count": {
        "votes": 15,
        "copies": 59
      },
      "difficulty": "ADVANCED",
      "language": "Python",
      "framework": "PyTorch",
      "lastUpdated": "2024-12-01",
      "featured": true
    }
  ],
  "meta": {
    "total": 11,
    "type": "CONFIGURATION",
    "generated_at": "2025-07-31T10:20:52.211Z"
  }
}